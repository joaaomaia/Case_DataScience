{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e25315e",
   "metadata": {},
   "source": [
    "# Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293d8361",
   "metadata": {},
   "source": [
    "## Setup & visão geral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef13ec",
   "metadata": {},
   "source": [
    "> Objetivo: Garantir reprodutibilidade e contexto regulatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60799efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Criar o ambiente Conda com Python 3.11\n",
    "# conda create -n ENV_PICPAY python=3.11\n",
    "\n",
    "# 2. Ativar o ambiente\n",
    "# conda activate ENV_PICPAY\n",
    "\n",
    "# 3. Instalar os pacotes listados em requirements.txt\n",
    "# pip install -r requirements.txt\n",
    "\n",
    "\n",
    "# importação de bibliotecas\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import warnings, os, random\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    matthews_corrcoef, \n",
    "    precision_score, \n",
    "    roc_auc_score, \n",
    "    brier_score_loss\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "# Caminho relativo para a pasta src (do notebook para a raiz e depois src\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "from utils import CreditRiskEDA, FeatureRelationshipInspector\n",
    "from audit_trail import AuditTrail\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2616f",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c702f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_dtypes(df, limite_categorico=50, force_categorical=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Identifica colunas numéricas e categóricas em um DataFrame.\n",
    "\n",
    "    - Força 'client_id' e colunas em `force_categorical` como categóricas, se existirem.\n",
    "    - Colunas object/string com poucos valores únicos viram 'category'.\n",
    "    - Colunas numéricas permanecem como estão.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df: DataFrame de entrada\n",
    "    - limite_categorico: máximo de valores únicos para considerar como 'category'\n",
    "    - force_categorical: lista de colunas que devem ser tratadas como categóricas\n",
    "    - verbose: se True, imprime detalhes das decisões\n",
    "\n",
    "    Retorna:\n",
    "    - num_cols: lista de colunas numéricas\n",
    "    - cat_cols: lista de colunas categóricas\n",
    "    \"\"\"\n",
    "    num_cols = []\n",
    "    cat_cols = []\n",
    "\n",
    "    if force_categorical is None:\n",
    "        force_categorical = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        tipo = df[col].dtype\n",
    "\n",
    "        # Força colunas explicitamente marcadas como categóricas\n",
    "        if col == 'client_id' or col in force_categorical:\n",
    "            cat_cols.append(col)\n",
    "            if verbose:\n",
    "                print(f\"Forçando '{col}' como categórica.\")\n",
    "            continue\n",
    "\n",
    "        if tipo == 'object' or tipo.name == 'string':\n",
    "            unicos = df[col].nunique(dropna=True)\n",
    "            if unicos <= limite_categorico:\n",
    "                cat_cols.append(col)\n",
    "                if verbose:\n",
    "                    print(f\"Coluna '{col}' classificada como 'category' ({unicos} únicos).\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"Coluna '{col}' tem muitos valores únicos ({unicos}), ignorada.\")\n",
    "        elif pd.api.types.is_numeric_dtype(tipo):\n",
    "            num_cols.append(col)\n",
    "        elif pd.api.types.is_bool_dtype(tipo):\n",
    "            cat_cols.append(col)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"Coluna '{col}' ignorada (tipo: {tipo}).\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f'\\nVariáveis categóricas ({len(cat_cols)}):')\n",
    "        for col in cat_cols:\n",
    "            print('> ', col)\n",
    "\n",
    "        print(f'\\nVariáveis numéricas ({len(num_cols)}):')\n",
    "        for col in num_cols:\n",
    "            print('> ', col)\n",
    "\n",
    "    return num_cols, cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43748f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10738, 81)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>safra</th>\n",
       "      <th>y</th>\n",
       "      <th>VAR_1</th>\n",
       "      <th>VAR_2</th>\n",
       "      <th>VAR_3</th>\n",
       "      <th>VAR_4</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>VAR_6</th>\n",
       "      <th>VAR_7</th>\n",
       "      <th>VAR_8</th>\n",
       "      <th>VAR_9</th>\n",
       "      <th>VAR_10</th>\n",
       "      <th>VAR_11</th>\n",
       "      <th>VAR_12</th>\n",
       "      <th>VAR_13</th>\n",
       "      <th>VAR_14</th>\n",
       "      <th>VAR_15</th>\n",
       "      <th>VAR_16</th>\n",
       "      <th>VAR_17</th>\n",
       "      <th>VAR_18</th>\n",
       "      <th>VAR_19</th>\n",
       "      <th>VAR_20</th>\n",
       "      <th>VAR_21</th>\n",
       "      <th>VAR_22</th>\n",
       "      <th>VAR_23</th>\n",
       "      <th>VAR_24</th>\n",
       "      <th>VAR_25</th>\n",
       "      <th>VAR_26</th>\n",
       "      <th>VAR_27</th>\n",
       "      <th>VAR_28</th>\n",
       "      <th>VAR_29</th>\n",
       "      <th>VAR_30</th>\n",
       "      <th>VAR_31</th>\n",
       "      <th>VAR_32</th>\n",
       "      <th>VAR_33</th>\n",
       "      <th>VAR_34</th>\n",
       "      <th>VAR_35</th>\n",
       "      <th>VAR_36</th>\n",
       "      <th>VAR_37</th>\n",
       "      <th>VAR_38</th>\n",
       "      <th>VAR_39</th>\n",
       "      <th>VAR_40</th>\n",
       "      <th>VAR_41</th>\n",
       "      <th>VAR_42</th>\n",
       "      <th>VAR_43</th>\n",
       "      <th>VAR_44</th>\n",
       "      <th>VAR_45</th>\n",
       "      <th>VAR_46</th>\n",
       "      <th>VAR_47</th>\n",
       "      <th>VAR_48</th>\n",
       "      <th>VAR_49</th>\n",
       "      <th>VAR_50</th>\n",
       "      <th>VAR_51</th>\n",
       "      <th>VAR_52</th>\n",
       "      <th>VAR_53</th>\n",
       "      <th>VAR_54</th>\n",
       "      <th>VAR_55</th>\n",
       "      <th>VAR_56</th>\n",
       "      <th>VAR_57</th>\n",
       "      <th>VAR_58</th>\n",
       "      <th>VAR_59</th>\n",
       "      <th>VAR_60</th>\n",
       "      <th>VAR_61</th>\n",
       "      <th>VAR_62</th>\n",
       "      <th>VAR_63</th>\n",
       "      <th>VAR_64</th>\n",
       "      <th>VAR_65</th>\n",
       "      <th>VAR_66</th>\n",
       "      <th>VAR_67</th>\n",
       "      <th>VAR_68</th>\n",
       "      <th>VAR_69</th>\n",
       "      <th>VAR_70</th>\n",
       "      <th>VAR_71</th>\n",
       "      <th>VAR_72</th>\n",
       "      <th>VAR_73</th>\n",
       "      <th>VAR_74</th>\n",
       "      <th>VAR_75</th>\n",
       "      <th>VAR_76</th>\n",
       "      <th>VAR_77</th>\n",
       "      <th>VAR_78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>201404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.54</td>\n",
       "      <td>3277.0</td>\n",
       "      <td>51.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.00</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.0</td>\n",
       "      <td>73.26</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>26.98</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.67</td>\n",
       "      <td>492.84</td>\n",
       "      <td>12.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>500.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.133833</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>220.84</td>\n",
       "      <td>348.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>512.82</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.28</td>\n",
       "      <td>379.0</td>\n",
       "      <td>53.97</td>\n",
       "      <td>3380.00</td>\n",
       "      <td>500.00</td>\n",
       "      <td>159.28</td>\n",
       "      <td>159.28</td>\n",
       "      <td>45</td>\n",
       "      <td>369.0</td>\n",
       "      <td>95.54</td>\n",
       "      <td>-0.030478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>159.28</td>\n",
       "      <td>0</td>\n",
       "      <td>1303.79</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>156.38</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>477.84</td>\n",
       "      <td>173.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>201407</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.92</td>\n",
       "      <td>2443.0</td>\n",
       "      <td>84.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>649.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.0</td>\n",
       "      <td>38.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>177.39</td>\n",
       "      <td>335.44</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>842.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.133833</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>338.90</td>\n",
       "      <td>179.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>269.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>228.0</td>\n",
       "      <td>97.73</td>\n",
       "      <td>0.357324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>836.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1486.26</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>707.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.69</td>\n",
       "      <td>54.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>201405</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.38</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>26.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1893.35</td>\n",
       "      <td>346.0</td>\n",
       "      <td>29.98</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.55</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>116.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.25</td>\n",
       "      <td>362.71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>597.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1893.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.133833</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>294.20</td>\n",
       "      <td>1893.35</td>\n",
       "      <td>1893.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>264.0</td>\n",
       "      <td>294.57</td>\n",
       "      <td>-0.411787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>800.27</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>471.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>732.00</td>\n",
       "      <td>121.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   safra  y  VAR_1  VAR_2  VAR_3  VAR_4   VAR_5   VAR_6  VAR_7  VAR_8   VAR_9   VAR_10  VAR_11  VAR_12  VAR_13  VAR_14  VAR_15  VAR_16  VAR_17  VAR_18  VAR_19  VAR_20  VAR_21  VAR_22  VAR_23  VAR_24  VAR_25  VAR_26  VAR_27  VAR_28  VAR_29  VAR_30   VAR_31   VAR_32   VAR_33  VAR_34  VAR_35  VAR_36  VAR_37  VAR_38  VAR_39  VAR_40  VAR_41  VAR_42  VAR_43  VAR_44  VAR_45  VAR_46  VAR_47  VAR_48  VAR_49  VAR_50  VAR_51  VAR_52  VAR_53   VAR_54   VAR_55  VAR_56  VAR_57  VAR_58  VAR_59   VAR_60   VAR_61  VAR_62  VAR_63  VAR_64  VAR_65   VAR_66  VAR_67  VAR_68  VAR_69  VAR_70  VAR_71  VAR_72  VAR_73  VAR_74  VAR_75  VAR_76  VAR_77  VAR_78\n",
       "0   1  201404  0   0.0    0.0    0.0    0.0   124.54  3277.0  51.98  NaN     500.00   153.0     NaN   299.0   73.26  1024.0   26.98   162.0  3000.0   72.0    45.0      8    1279.0   63.0    77.67  492.84   12.0    845.0     NaN   12.0    16.0    500.00   22.0   0.133833   18.0    NaN       NaN    0.0    16.0   220.84   348.0    9.0    9.57    33.0    19.0    11.0   512.82   36.0     0.0    16.0     0.0   159.28   379.0   53.97  3380.00   500.00  159.28  159.28    45     369.0   95.54 -0.030478    0.0   2508.0  159.28     0    1303.79    8.0   -69.0    16.0   156.38   7.52     0.0    151.0    0.0     3.0   477.84  173.06    0.00    3.0 \n",
       "1   2  201407  0  64.0    0.0    2.0    1.0    47.92  2443.0  84.72  NaN    1000.00   649.0     NaN   224.0   38.53     NaN     NaN    84.0     NaN   50.0    18.0     12    1063.0   31.0   177.39  335.44    9.0      NaN   842.0   10.0     NaN   1000.00   14.0   0.133833   13.0    NaN       NaN    NaN     NaN   338.90   179.0    5.0     NaN     NaN    19.0     9.0   269.71    NaN     0.0     NaN     NaN      NaN     NaN     NaN  1000.00  2000.00     NaN     NaN    60     228.0   97.73  0.357324    NaN    836.0     NaN     0    1486.26   24.0     NaN     NaN   707.84    NaN     NaN    187.0    NaN     NaN      NaN  184.69   54.00    NaN \n",
       "2   3  201405  0  99.0    2.0    2.0    2.0    80.38  1824.0  26.63  NaN    1893.35   346.0   29.98   106.0     NaN     NaN   73.55     8.0     NaN    3.0     2.0     12     116.0    4.0   140.25  362.71    3.0      NaN   597.0    5.0     NaN   1893.35    NaN   0.133833    2.0    NaN     59.97    NaN     NaN   133.17     NaN    4.0     NaN     NaN     3.0    12.0      NaN    NaN     0.0     NaN     NaN      NaN     NaN  294.20  1893.35  1893.35     NaN     NaN    31     264.0  294.57 -0.411787    NaN      NaN     NaN     0     800.27   18.0     NaN     NaN   471.86    NaN     NaN     96.0    NaN     NaN      NaN  732.00  121.98    NaN "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../data/raw/base_modelo.csv')\n",
    "\n",
    "print(raw_data.shape)\n",
    "\n",
    "display(raw_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3501b",
   "metadata": {},
   "source": [
    "### 📄 Estrutura Geral do Dataset (`raw_data`)\n",
    "\n",
    "| Coluna    | Tipo Esperado | Descrição Simplificada                    |\n",
    "|-----------|---------------|-------------------------------------------|\n",
    "| `id`      | int           | Identificador único do registro           |\n",
    "| `safra`   | int           | Ano e mês da Safra de Originação (formato YYYYMM)  |\n",
    "| `y`       | int (0 ou 1)  | Variável alvo (ex: inadimplência)         |\n",
    "| `VAR_1`   | float         | Variável anônima                          |\n",
    "| `VAR_2`   | float         | Variável anônima                          |\n",
    "| `VAR_3`   | float         | Variável anônima                          |\n",
    "| ...       | ...           | ... até                                   |\n",
    "| `VAR_78`  | float         | Variável anônima                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a6014",
   "metadata": {},
   "source": [
    "#### Definição de Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4eb14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 📊 Tipos de Variáveis Detectadas"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Variáveis Numéricas: 78\n",
      "🔣 Variáveis Categóricas: 0\n",
      "\n",
      "🧮 Numéricas:\n",
      "VAR_1, VAR_2, VAR_3, VAR_4, VAR_5, VAR_6, VAR_7, VAR_8, VAR_9, VAR_10...\n",
      "\n",
      "🔠 Categóricas:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerical_cols, categorical_cols = search_dtypes(\n",
    "    raw_data.drop(columns=['id', 'safra', 'y']),  # ignora identificadores e target\n",
    "    force_categorical=[],                         # permite auto-identificação\n",
    "    limite_categorico=50,                         # colunas com até 50 valores únicos = categóricas\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "display(Markdown(\"### 📊 Tipos de Variáveis Detectadas\"))\n",
    "print(f\"🔢 Variáveis Numéricas: {len(numerical_cols)}\")\n",
    "print(f\"🔣 Variáveis Categóricas: {len(categorical_cols)}\")\n",
    "\n",
    "print(\"\\n🧮 Numéricas:\")\n",
    "print(\", \".join(numerical_cols[:10]) + (\"...\" if len(numerical_cols) > 10 else \"\"))\n",
    "\n",
    "print(\"\\n🔠 Categóricas:\")\n",
    "print(\", \".join(categorical_cols[:10]) + (\"...\" if len(categorical_cols) > 10 else \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7919e0",
   "metadata": {},
   "source": [
    "# Seção 1 - Qualidade dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f75a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Período de concessão do crédito:\n",
      "🔹 Safra mais antiga: 201401\n",
      "🔹 Safra mais recente: 201412\n",
      "🔢 Total de safras distintas: 12 meses\n"
     ]
    }
   ],
   "source": [
    "print(f\"📅 Período de concessão do crédito:\")\n",
    "print(f\"🔹 Safra mais antiga: {raw_data['safra'].min()}\")\n",
    "print(f\"🔹 Safra mais recente: {raw_data['safra'].max()}\")\n",
    "print(f\"🔢 Total de safras distintas: {raw_data['safra'].nunique()} meses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb6107",
   "metadata": {},
   "source": [
    "### 🔎 Verificação de Duplicidade em ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75c8b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📌 Verificação de Duplicidades no Identificador Primário (id)\n",
      "============================================================\n",
      "👥 Total de linhas: 10,738\n",
      "🔑 Total de IDs únicos: 10,738\n",
      "⚠️  IDs duplicados encontrados: 0\n",
      "============================================================\n",
      "✅ Nenhuma duplicidade encontrada no campo 'id'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dup_count = raw_data.duplicated(subset='id').sum()\n",
    "total_ids = raw_data['id'].nunique()\n",
    "total_rows = len(raw_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📌 Verificação de Duplicidades no Identificador Primário (id)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"👥 Total de linhas: {total_rows:,}\")\n",
    "print(f\"🔑 Total de IDs únicos: {total_ids:,}\")\n",
    "print(f\"⚠️  IDs duplicados encontrados: {dup_count:,}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if dup_count == 0:\n",
    "    print(\"✅ Nenhuma duplicidade encontrada no campo 'id'.\\n\")\n",
    "else:\n",
    "    print(\"❗ Existem registros duplicados. Investigar antes de seguir com o modelo.\\n\")\n",
    "\n",
    "if dup_count > 0:\n",
    "    display(raw_data[raw_data.duplicated(subset='id', keep=False)].sort_values('id').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403e22f",
   "metadata": {},
   "source": [
    "#### Dados Ausentes, zeros e outliers (z-score/IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33be6530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🔍 Foram encontradas 72 colunas com dados ausentes.\n",
      "🧮 Percentual de valores ausentes por coluna:\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pct_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>safra</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAR_32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VAR_20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VAR_57</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VAR_60</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VAR_64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VAR_9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VAR_30</td>\n",
       "      <td>0.447011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VAR_33</td>\n",
       "      <td>0.568076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VAR_28</td>\n",
       "      <td>0.568076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VAR_25</td>\n",
       "      <td>0.568076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VAR_40</td>\n",
       "      <td>0.568076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>VAR_22</td>\n",
       "      <td>0.568076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>VAR_19</td>\n",
       "      <td>0.568076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VAR_44</td>\n",
       "      <td>0.568076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VAR_72</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VAR_6</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VAR_1</td>\n",
       "      <td>3.874092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VAR_4</td>\n",
       "      <td>3.874092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VAR_3</td>\n",
       "      <td>3.874092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VAR_2</td>\n",
       "      <td>3.874092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VAR_54</td>\n",
       "      <td>11.873720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VAR_53</td>\n",
       "      <td>16.381077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VAR_65</td>\n",
       "      <td>20.851183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>VAR_24</td>\n",
       "      <td>37.809648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>VAR_58</td>\n",
       "      <td>37.809648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>VAR_5</td>\n",
       "      <td>37.809648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VAR_17</td>\n",
       "      <td>41.916558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VAR_76</td>\n",
       "      <td>42.382194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>VAR_59</td>\n",
       "      <td>42.382194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>VAR_38</td>\n",
       "      <td>43.136524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>VAR_7</td>\n",
       "      <td>43.136524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>VAR_34</td>\n",
       "      <td>45.008381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VAR_8</td>\n",
       "      <td>45.008381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>VAR_35</td>\n",
       "      <td>46.414602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VAR_11</td>\n",
       "      <td>46.414602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>VAR_15</td>\n",
       "      <td>47.066493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VAR_52</td>\n",
       "      <td>47.066493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>VAR_13</td>\n",
       "      <td>48.593779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>VAR_39</td>\n",
       "      <td>48.593779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>VAR_45</td>\n",
       "      <td>48.593779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>VAR_51</td>\n",
       "      <td>51.601788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>VAR_71</td>\n",
       "      <td>51.601788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>VAR_78</td>\n",
       "      <td>51.601788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>VAR_73</td>\n",
       "      <td>51.601788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>VAR_74</td>\n",
       "      <td>51.601788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>VAR_26</td>\n",
       "      <td>51.601788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>VAR_14</td>\n",
       "      <td>51.601788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>VAR_69</td>\n",
       "      <td>51.825293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>VAR_23</td>\n",
       "      <td>51.825293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>VAR_66</td>\n",
       "      <td>51.825293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>VAR_10</td>\n",
       "      <td>51.825293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>VAR_77</td>\n",
       "      <td>51.825293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>VAR_46</td>\n",
       "      <td>52.626187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>VAR_42</td>\n",
       "      <td>53.659899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>VAR_31</td>\n",
       "      <td>54.302477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>VAR_27</td>\n",
       "      <td>55.261687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>VAR_29</td>\n",
       "      <td>55.364127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>VAR_37</td>\n",
       "      <td>56.900726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>VAR_67</td>\n",
       "      <td>57.208046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>VAR_48</td>\n",
       "      <td>59.526914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>VAR_50</td>\n",
       "      <td>61.547774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>VAR_68</td>\n",
       "      <td>61.547774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>VAR_55</td>\n",
       "      <td>63.885267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>VAR_56</td>\n",
       "      <td>64.388154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>VAR_41</td>\n",
       "      <td>65.412554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>VAR_75</td>\n",
       "      <td>65.412554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>VAR_47</td>\n",
       "      <td>66.166884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>VAR_16</td>\n",
       "      <td>66.185509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>VAR_21</td>\n",
       "      <td>66.334513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>VAR_18</td>\n",
       "      <td>66.334513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>VAR_43</td>\n",
       "      <td>67.023654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>VAR_12</td>\n",
       "      <td>67.023654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>VAR_63</td>\n",
       "      <td>67.470665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>VAR_36</td>\n",
       "      <td>67.684858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>VAR_49</td>\n",
       "      <td>67.945614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>VAR_61</td>\n",
       "      <td>71.316819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>VAR_70</td>\n",
       "      <td>76.913764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>VAR_62</td>\n",
       "      <td>78.012665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index   pct_missing\n",
       "0       id    0.000000 \n",
       "1    safra    0.000000 \n",
       "2        y    0.000000 \n",
       "3   VAR_32    0.000000 \n",
       "4   VAR_20    0.000000 \n",
       "5   VAR_57    0.000000 \n",
       "6   VAR_60    0.000000 \n",
       "7   VAR_64    0.000000 \n",
       "8    VAR_9    0.000000 \n",
       "9   VAR_30    0.447011 \n",
       "10  VAR_33    0.568076 \n",
       "11  VAR_28    0.568076 \n",
       "12  VAR_25    0.568076 \n",
       "13  VAR_40    0.568076 \n",
       "14  VAR_22    0.568076 \n",
       "15  VAR_19    0.568076 \n",
       "16  VAR_44    0.568076 \n",
       "17  VAR_72    0.847458 \n",
       "18   VAR_6    0.847458 \n",
       "19   VAR_1    3.874092 \n",
       "20   VAR_4    3.874092 \n",
       "21   VAR_3    3.874092 \n",
       "22   VAR_2    3.874092 \n",
       "23  VAR_54   11.873720 \n",
       "24  VAR_53   16.381077 \n",
       "25  VAR_65   20.851183 \n",
       "26  VAR_24   37.809648 \n",
       "27  VAR_58   37.809648 \n",
       "28   VAR_5   37.809648 \n",
       "29  VAR_17   41.916558 \n",
       "30  VAR_76   42.382194 \n",
       "31  VAR_59   42.382194 \n",
       "32  VAR_38   43.136524 \n",
       "33   VAR_7   43.136524 \n",
       "34  VAR_34   45.008381 \n",
       "35   VAR_8   45.008381 \n",
       "36  VAR_35   46.414602 \n",
       "37  VAR_11   46.414602 \n",
       "38  VAR_15   47.066493 \n",
       "39  VAR_52   47.066493 \n",
       "40  VAR_13   48.593779 \n",
       "41  VAR_39   48.593779 \n",
       "42  VAR_45   48.593779 \n",
       "43  VAR_51   51.601788 \n",
       "44  VAR_71   51.601788 \n",
       "45  VAR_78   51.601788 \n",
       "46  VAR_73   51.601788 \n",
       "47  VAR_74   51.601788 \n",
       "48  VAR_26   51.601788 \n",
       "49  VAR_14   51.601788 \n",
       "50  VAR_69   51.825293 \n",
       "51  VAR_23   51.825293 \n",
       "52  VAR_66   51.825293 \n",
       "53  VAR_10   51.825293 \n",
       "54  VAR_77   51.825293 \n",
       "55  VAR_46   52.626187 \n",
       "56  VAR_42   53.659899 \n",
       "57  VAR_31   54.302477 \n",
       "58  VAR_27   55.261687 \n",
       "59  VAR_29   55.364127 \n",
       "60  VAR_37   56.900726 \n",
       "61  VAR_67   57.208046 \n",
       "62  VAR_48   59.526914 \n",
       "63  VAR_50   61.547774 \n",
       "64  VAR_68   61.547774 \n",
       "65  VAR_55   63.885267 \n",
       "66  VAR_56   64.388154 \n",
       "67  VAR_41   65.412554 \n",
       "68  VAR_75   65.412554 \n",
       "69  VAR_47   66.166884 \n",
       "70  VAR_16   66.185509 \n",
       "71  VAR_21   66.334513 \n",
       "72  VAR_18   66.334513 \n",
       "73  VAR_43   67.023654 \n",
       "74  VAR_12   67.023654 \n",
       "75  VAR_63   67.470665 \n",
       "76  VAR_36   67.684858 \n",
       "77  VAR_49   67.945614 \n",
       "78  VAR_61   71.316819 \n",
       "79  VAR_70   76.913764 \n",
       "80  VAR_62   78.012665 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 📊 Análise de Dados Ausentes\n",
    "missing = (raw_data.isna().mean() * 100).sort_values(ascending=True)\n",
    "total_missing = (missing > 0).sum()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🔍 Foram encontradas {total_missing} colunas com dados ausentes.\")\n",
    "print(\"🧮 Percentual de valores ausentes por coluna:\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "missing = missing.to_frame('pct_missing').reset_index()\n",
    "\n",
    "display(missing.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015aa33e",
   "metadata": {},
   "source": [
    "> A quantidade de dados ausentes podem ajudar a nortear a decisão por modelos mais robustos que modelos lineares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb8c07",
   "metadata": {},
   "source": [
    "### 📊 Verificação de Outliers (Z-Score > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1827d039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🚨 Verificação de Outliers em Colunas Numéricas\n",
      "Critério: Z-Score absoluto > 3\n",
      "============================================================\n",
      "🧮 Total de colunas numéricas analisadas: 78\n",
      "🔝 Colunas com maior percentual de outliers:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>pct_outliers&gt;3σ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VAR_33</th>\n",
       "      <td>2.831067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_19</th>\n",
       "      <td>2.728627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_72</th>\n",
       "      <td>2.710002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_22</th>\n",
       "      <td>2.588936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_3</th>\n",
       "      <td>2.411995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_1</th>\n",
       "      <td>2.216428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_4</th>\n",
       "      <td>2.141926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_65</th>\n",
       "      <td>2.104675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_54</th>\n",
       "      <td>1.937046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_53</th>\n",
       "      <td>1.862544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_2</th>\n",
       "      <td>1.788042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_30</th>\n",
       "      <td>1.676290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_71</th>\n",
       "      <td>1.611101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_73</th>\n",
       "      <td>1.592475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_74</th>\n",
       "      <td>1.192028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_78</th>\n",
       "      <td>1.182716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_5</th>\n",
       "      <td>1.182716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_58</th>\n",
       "      <td>1.145465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_76</th>\n",
       "      <td>1.136152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_67</th>\n",
       "      <td>1.098901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_45</th>\n",
       "      <td>1.089588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_24</th>\n",
       "      <td>1.089588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_39</th>\n",
       "      <td>1.052337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_13</th>\n",
       "      <td>1.015087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_17</th>\n",
       "      <td>0.996461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_51</th>\n",
       "      <td>0.977836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_31</th>\n",
       "      <td>0.959210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_38</th>\n",
       "      <td>0.949898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_7</th>\n",
       "      <td>0.931272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_15</th>\n",
       "      <td>0.921959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_23</th>\n",
       "      <td>0.912647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_59</th>\n",
       "      <td>0.912647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_52</th>\n",
       "      <td>0.884709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_34</th>\n",
       "      <td>0.866083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_35</th>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_77</th>\n",
       "      <td>0.838145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_69</th>\n",
       "      <td>0.828832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_10</th>\n",
       "      <td>0.819519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_66</th>\n",
       "      <td>0.800894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_11</th>\n",
       "      <td>0.782269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_47</th>\n",
       "      <td>0.754330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_21</th>\n",
       "      <td>0.717080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_18</th>\n",
       "      <td>0.679829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_68</th>\n",
       "      <td>0.651890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_75</th>\n",
       "      <td>0.651890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_29</th>\n",
       "      <td>0.642578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_48</th>\n",
       "      <td>0.623952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_43</th>\n",
       "      <td>0.623952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_8</th>\n",
       "      <td>0.614640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_37</th>\n",
       "      <td>0.614640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_12</th>\n",
       "      <td>0.605327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_16</th>\n",
       "      <td>0.568076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_41</th>\n",
       "      <td>0.530825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_49</th>\n",
       "      <td>0.530825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_61</th>\n",
       "      <td>0.530825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_26</th>\n",
       "      <td>0.521512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_62</th>\n",
       "      <td>0.493574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_70</th>\n",
       "      <td>0.484262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_36</th>\n",
       "      <td>0.474949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_46</th>\n",
       "      <td>0.447011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_42</th>\n",
       "      <td>0.437698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_63</th>\n",
       "      <td>0.428385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_14</th>\n",
       "      <td>0.344571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_50</th>\n",
       "      <td>0.325945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_55</th>\n",
       "      <td>0.288694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_32</th>\n",
       "      <td>0.251443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_56</th>\n",
       "      <td>0.223505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_6</th>\n",
       "      <td>0.027938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_60</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_64</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_57</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_27</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_44</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAR_40</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pct_outliers>3σ\n",
       "VAR_33     2.831067    \n",
       "VAR_19     2.728627    \n",
       "VAR_72     2.710002    \n",
       "VAR_22     2.588936    \n",
       "VAR_3      2.411995    \n",
       "VAR_1      2.216428    \n",
       "VAR_4      2.141926    \n",
       "VAR_65     2.104675    \n",
       "VAR_54     1.937046    \n",
       "VAR_53     1.862544    \n",
       "VAR_2      1.788042    \n",
       "VAR_30     1.676290    \n",
       "VAR_71     1.611101    \n",
       "VAR_73     1.592475    \n",
       "VAR_74     1.192028    \n",
       "VAR_78     1.182716    \n",
       "VAR_5      1.182716    \n",
       "VAR_58     1.145465    \n",
       "VAR_76     1.136152    \n",
       "VAR_67     1.098901    \n",
       "VAR_45     1.089588    \n",
       "VAR_24     1.089588    \n",
       "VAR_39     1.052337    \n",
       "VAR_13     1.015087    \n",
       "VAR_17     0.996461    \n",
       "VAR_51     0.977836    \n",
       "VAR_31     0.959210    \n",
       "VAR_38     0.949898    \n",
       "VAR_7      0.931272    \n",
       "VAR_15     0.921959    \n",
       "VAR_23     0.912647    \n",
       "VAR_59     0.912647    \n",
       "VAR_52     0.884709    \n",
       "VAR_34     0.866083    \n",
       "VAR_35     0.847458    \n",
       "VAR_77     0.838145    \n",
       "VAR_69     0.828832    \n",
       "VAR_10     0.819519    \n",
       "VAR_66     0.800894    \n",
       "VAR_11     0.782269    \n",
       "VAR_47     0.754330    \n",
       "VAR_21     0.717080    \n",
       "VAR_18     0.679829    \n",
       "VAR_68     0.651890    \n",
       "VAR_75     0.651890    \n",
       "VAR_29     0.642578    \n",
       "VAR_48     0.623952    \n",
       "VAR_43     0.623952    \n",
       "VAR_8      0.614640    \n",
       "VAR_37     0.614640    \n",
       "VAR_12     0.605327    \n",
       "VAR_16     0.568076    \n",
       "VAR_41     0.530825    \n",
       "VAR_49     0.530825    \n",
       "VAR_61     0.530825    \n",
       "VAR_26     0.521512    \n",
       "VAR_62     0.493574    \n",
       "VAR_70     0.484262    \n",
       "VAR_36     0.474949    \n",
       "VAR_46     0.447011    \n",
       "VAR_42     0.437698    \n",
       "VAR_63     0.428385    \n",
       "VAR_14     0.344571    \n",
       "VAR_50     0.325945    \n",
       "VAR_55     0.288694    \n",
       "VAR_32     0.251443    \n",
       "VAR_56     0.223505    \n",
       "VAR_6      0.027938    \n",
       "VAR_60     0.000000    \n",
       "VAR_64     0.000000    \n",
       "VAR_9      0.000000    \n",
       "VAR_57     0.000000    \n",
       "VAR_28     0.000000    \n",
       "VAR_27     0.000000    \n",
       "VAR_44     0.000000    \n",
       "VAR_25     0.000000    \n",
       "VAR_20     0.000000    \n",
       "VAR_40     0.000000    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🚨 Verificação de Outliers em Colunas Numéricas\")\n",
    "print(\"Critério: Z-Score absoluto > 3\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "outlier_summary = {}\n",
    "for col in numerical_cols:\n",
    "    try:\n",
    "        z = np.abs(stats.zscore(raw_data[col].dropna()))\n",
    "        outlier_pct = (z > 3).sum() / len(raw_data) * 100\n",
    "        outlier_summary[col] = outlier_pct\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Falha ao calcular z-score para '{col}': {e}\")\n",
    "\n",
    "outlier_df = pd.Series(outlier_summary).sort_values(ascending=False)\n",
    "\n",
    "print(f\"🧮 Total de colunas numéricas analisadas: {len(outlier_df)}\")\n",
    "print(\"🔝 Colunas com maior percentual de outliers:\\n\")\n",
    "\n",
    "display(outlier_df.to_frame('pct_outliers>3σ').head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25af60",
   "metadata": {},
   "source": [
    "### 🔍 Identificação e Remoção de Colunas com Valor Único"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17849949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🧹 Verificação de Colunas com Valor Único (excluindo NaN)\n",
      "============================================================\n",
      "✅ Nenhuma coluna com valor único encontrada.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🧹 Verificação de Colunas com Valor Único (excluindo NaN)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "unique_cols = [\n",
    "    col for col in raw_data.columns \n",
    "    if raw_data[col].nunique(dropna=True) == 1\n",
    "]\n",
    "\n",
    "if unique_cols:\n",
    "    print(f\"🔎 Foram encontradas {len(unique_cols)} colunas com valor único:\")\n",
    "    for col in unique_cols:\n",
    "        unique_val = raw_data[col].dropna().unique()\n",
    "        val_str = unique_val[0] if len(unique_val) > 0 else 'NaN'\n",
    "        print(f\"  - {col}: {val_str}\")\n",
    "    \n",
    "    # ✂️ Remoção\n",
    "    raw_data.drop(columns=unique_cols, inplace=True)\n",
    "    print(f\"✅ Colunas removidas: {unique_cols}\")\n",
    "else:\n",
    "    print(\"✅ Nenhuma coluna com valor único encontrada.\")\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3606f816",
   "metadata": {},
   "source": [
    "# Seção 2 – Target & Desbalanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a896e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event rate (inadimplência): 29.13%\n"
     ]
    }
   ],
   "source": [
    "TARGET_COL = 'y'\n",
    "\n",
    "event_rate = raw_data[TARGET_COL].mean()\n",
    "print(f'Event rate (inadimplência): {event_rate:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea225284",
   "metadata": {},
   "source": [
    "#### Target (y) representaria Inadimplência Presente ou Futura?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a5e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ser inadimplência presente, precisaria que todos os valores após determinado limiar de atraso implicassem em y=1\n",
    "\n",
    "# possível localizar isso?\n",
    "\n",
    "# alguma coluna poderia ser a melhor candidata a ser dias_atraso?\n",
    "\n",
    "# como identificar?\n",
    "\n",
    "# resposta: a feature com maior correlação com target tem chance de ser dias_atraso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e4cc9",
   "metadata": {},
   "source": [
    "#### Qual feature tem mais chance de representar DPD (dias de atraso) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f64dddd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontradas 65 colunas numéricas com valores não-negativos.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- IDENTIFICAR CANDIDATAS (NUMÉRICAS E NÃO-NEGATIVAS) ---\n",
    "candidate_columns = []\n",
    "for col in raw_data.columns:\n",
    "    # Ignorar colunas que não são features, como id, safra e a própria alvo\n",
    "    if col in ['id', 'safra', 'y']:\n",
    "        continue\n",
    "    \n",
    "    # Verificar se a coluna é numérica e se o valor mínimo é >= 0\n",
    "    if pd.api.types.is_numeric_dtype(raw_data[col]):\n",
    "        if raw_data[col].min(skipna=True) >= 0:\n",
    "            candidate_columns.append(col)\n",
    "\n",
    "print(f\"Encontradas {len(candidate_columns)} colunas numéricas com valores não-negativos.\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0978d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlação com a variável alvo 'y' (inadimplência)\n",
      "Principal candidata a 'dias de atraso': 'VAR_1'\n",
      "Valor da Correlação: 0.3360\n",
      "\n",
      "Top 5 candidatas:\n",
      "VAR_1     0.336045\n",
      "VAR_2     0.215004\n",
      "VAR_20    0.167523\n",
      "VAR_3     0.157032\n",
      "VAR_49    0.149693\n",
      "dtype: float64\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- ENCONTRAR A MAIOR CORRELAÇÃO COM A INADIMPLÊNCIA (y) ---\n",
    "# Calcula a correlação de todas as candidatas com a variável 'y'\n",
    "correlations = raw_data[candidate_columns].corrwith(raw_data['y']).sort_values(ascending=False)\n",
    "\n",
    "# Pega o nome e o valor da coluna com a maior correlação positiva\n",
    "best_candidate_col = correlations.index[0]\n",
    "best_correlation_val = correlations.iloc[0]\n",
    "\n",
    "print(\"Correlação com a variável alvo 'y' (inadimplência)\")\n",
    "print(f\"Principal candidata a 'dias de atraso': '{best_candidate_col}'\")\n",
    "print(f\"Valor da Correlação: {best_correlation_val:.4f}\\n\")\n",
    "print(\"Top 5 candidatas:\")\n",
    "print(correlations.head())\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d5c2c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisando em detalhes a coluna 'VAR_1'...\n",
      "\n",
      "Estatísticas Descritivas:\n",
      "count    10322.000000\n",
      "mean        32.999225\n",
      "std         46.367685\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%         16.000000\n",
      "75%         46.000000\n",
      "max        208.000000\n",
      "Name: VAR_1, dtype: float64\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- ANÁLISE DETALHADA DA COLUNA SELECIONADA ---\n",
    "print(f\"Analisando em detalhes a coluna '{best_candidate_col}'...\\n\")\n",
    "\n",
    "# Exibir estatísticas descritivas\n",
    "print(\"Estatísticas Descritivas:\")\n",
    "print(raw_data[best_candidate_col].describe())\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c900cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como um contrato \"novo\" originado na safra atual, ter atraso superior a 30 dias?\n",
    "\n",
    "# Simples: o contrato pode ser fruto de reestruturação de contrato anterior\n",
    "\n",
    "# Neste caso, é importante que não haja re-aging (rejuvenecimento de condição de atraso), sob pena de subestimativa de risco.\n",
    "\n",
    "# após uma fase de default, os contratos passam por etapa de workout (redução de sua condição de inadimplência), para posterior cura\n",
    "\n",
    "# a cura é um período de prova de resiliência de saúde creditícia, onde o gap_cure deve ser construído com base em política de risco de crédito.\n",
    "\n",
    "# As 4966/21 não fecha um intervalo mínimo de cura, mas em geral se usam ao menos 3 meses sem quaisquer atrasos ou dívidas remanecentes.\n",
    "\n",
    "# Esse tempo de cura pode ser conforme segmentos de carteiras (com ou sem garantias fiduciárias)\n",
    "\n",
    "\n",
    "# Quanto maior o tempo de cura exigido, mais conservadora é a abordagem\n",
    "\n",
    "# pois o contrato permanece por mais tempo em estágios de maior risco, o que pode resultar em maior provisão de perda esperada (ECL) durante esse período."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e9b35",
   "metadata": {},
   "source": [
    "### Histograma de \"Dias de Atraso\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23838ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Preparação: Faixas de atraso ---\n",
    "coluna = best_candidate_col\n",
    "valores = raw_data[coluna].dropna()\n",
    "\n",
    "bins = [0, 30, 60, 90, valores.max()]\n",
    "labels = ['0–30 dias', '30–60 dias', '60–90 dias', '> 90 dias']\n",
    "faixas = pd.cut(valores, bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "\n",
    "frequencia = faixas.value_counts(sort=False)\n",
    "porcentagem = (frequencia / frequencia.sum() * 100).round(1)\n",
    "\n",
    "# --- Paleta de cores\n",
    "cor_fixa = sns.color_palette(\"Blues\")[3]\n",
    "PALETTE = ['#77BDD9', '#0A3873']  # y=0, y=1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "# --- Gráfico: Histograma por faixas ---\n",
    "sns.barplot(\n",
    "    x=frequencia.index,\n",
    "    y=frequencia.values,\n",
    "    color=cor_fixa,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Adiciona porcentagens sobre as barras\n",
    "for i, (count, pct) in enumerate(zip(frequencia.values, porcentagem.values)):\n",
    "    ax.text(i, count + count * 0.01, f'{pct}%', ha='center', va='bottom',\n",
    "            fontsize=11, fontweight='bold')\n",
    "\n",
    "# Customizações do gráfico\n",
    "ax.set_title(f'Critério 4: Faixas de {coluna}', fontsize=16)\n",
    "ax.set_xlabel('Faixa de Dias', fontsize=12)\n",
    "ax.set_ylabel('Contagem de Clientes', fontsize=12)\n",
    "ax.set_xticklabels(labels, fontsize=11)\n",
    "ax.set_yticks([])\n",
    "ax.grid(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ea58b",
   "metadata": {},
   "source": [
    "### 🔍 Análise de causalidade temporal: y é um evento futuro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab7291d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📌 Verificação de causalidade temporal entre 'VAR_1' e 'y'\n",
      "============================================================\n",
      "📄 Total de registros com VAR_1 ≥ 90 dias: 1,217\n",
      "🎯 Taxa de eventos (y=1) entre esses casos: 66.80%\n",
      "\n",
      "✅ Conclusão: Como nem todos os casos com VAR_1 ≥ 90 dias têm y = 1,\n",
      "presume‑se que 'y' representa inadimplência futura (a ser observada após a data atual).\n",
      "Ou seja, VAR_1 é uma variável explicativa (pré‑evento) e não consequência de y.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Parâmetros básicos\n",
    "VAR      = \"VAR_1\"   # variável explicativa (dias de atraso, por ex.)\n",
    "TARGET   = \"y\"       # target binário\n",
    "THRESH   = 90\n",
    "PALETTE  = ['#77BDD9', '#0A3873']  # y=0, y=1\n",
    "coluna   = VAR  # usado para o título do boxplot\n",
    "\n",
    "# --- Análise de causalidade temporal\n",
    "mask  = raw_data[VAR] >= THRESH\n",
    "total = mask.sum()\n",
    "rate  = raw_data.loc[mask, TARGET].mean() * 100 if total else 0.0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"📌 Verificação de causalidade temporal entre '{VAR}' e '{TARGET}'\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"📄 Total de registros com {VAR} ≥ {THRESH} dias: {total:,}\")\n",
    "print(f\"🎯 Taxa de eventos ({TARGET}=1) entre esses casos: {rate:.2f}%\\n\")\n",
    "\n",
    "if total == 0:\n",
    "    print(\"⚠️  Nenhum registro atende ao critério; análise inconclusiva.\")\n",
    "elif abs(rate - 100.0) < 1e-6:\n",
    "    print(\"❌ Conclusão: Todos os registros com \"\n",
    "          f\"{VAR} ≥ {THRESH} dias têm {TARGET} = 1, \"\n",
    "          \"indicando que a variável é consequência (pós‑evento) do target.\")\n",
    "else:\n",
    "    print(\"✅ Conclusão: Como nem todos os casos com \"\n",
    "          f\"{VAR} ≥ {THRESH} dias têm {TARGET} = 1,\\n\"\n",
    "          \"presume‑se que 'y' representa inadimplência futura (a ser observada após a data atual).\\n\"\n",
    "          f\"Ou seja, {VAR} é uma variável explicativa (pré‑evento) e não consequência de {TARGET}.\")\n",
    "\n",
    "# --- Gráfico: Boxplot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "sns.boxplot(\n",
    "    x=TARGET,\n",
    "    y=coluna,\n",
    "    data=raw_data,\n",
    "    palette=PALETTE,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title(f'{coluna} vs Status de Pagamento', fontsize=16)\n",
    "ax.set_xlabel('Status de Inadimplência (y=1 é mau pagador)', fontsize=12)\n",
    "ax.set_ylabel(f'Valores de {coluna}', fontsize=12)\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(['Bons Pagadores (y=0)', 'Futuros Maus Pagadores (y=1)'], fontsize=11)\n",
    "ax.grid(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa36465",
   "metadata": {},
   "source": [
    "### Volumetria de Contratos e Taxa de Inadimplência por Safra de Originação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0a90f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>Qtd. Contratos:</b> %{y:,}<extra></extra>",
         "marker": {
          "color": "silver"
         },
         "name": "Qtd. Contratos",
         "type": "bar",
         "x": [
          "2014-01",
          "2014-02",
          "2014-03",
          "2014-04",
          "2014-05",
          "2014-06",
          "2014-07",
          "2014-08",
          "2014-09",
          "2014-10",
          "2014-11",
          "2014-12"
         ],
         "y": {
          "bdata": "VgOCA2kDuwPMA4YDyAOQA20DpQMoAxID",
          "dtype": "i2"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>% Target (y):</b> %{y:.2f}%<extra></extra>",
         "line": {
          "color": "#11BF5D",
          "width": 2.5
         },
         "marker": {
          "color": "#11BF5D",
          "size": 6
         },
         "mode": "lines+markers",
         "name": "% Target (y)",
         "type": "scatter",
         "x": [
          "2014-01",
          "2014-02",
          "2014-03",
          "2014-04",
          "2014-05",
          "2014-06",
          "2014-07",
          "2014-08",
          "2014-09",
          "2014-10",
          "2014-11",
          "2014-12"
         ],
         "y": {
          "bdata": "lBt2sYhUQUCyh5K/sEo/QOUiITekUDlAzJjydVjCOUC8vw7GrDQ5QGNGLGbEYjpA7RC4sQzKO0DhPoL7CC48QGWtprkU/T1ABBEaTZuCPEBC7vrZYqVAQNJOjwTxnkFA",
          "dtype": "f8"
         },
         "yaxis": "y2"
        }
       ],
       "layout": {
        "height": 500,
        "hovermode": "x unified",
        "legend": {
         "bgcolor": "rgba(0,0,0,0)",
         "x": 0.01,
         "y": 0.99
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Evolução de Novos Contratos e Taxa de Inadimplência Futura por Safra"
        },
        "xaxis": {
         "tickangle": -45,
         "tickmode": "array",
         "ticktext": [
          "2014-01",
          "2014-02",
          "2014-03",
          "2014-04",
          "2014-05",
          "2014-06",
          "2014-07",
          "2014-08",
          "2014-09",
          "2014-10",
          "2014-11",
          "2014-12"
         ],
         "tickvals": [
          "2014-01",
          "2014-02",
          "2014-03",
          "2014-04",
          "2014-05",
          "2014-06",
          "2014-07",
          "2014-08",
          "2014-09",
          "2014-10",
          "2014-11",
          "2014-12"
         ],
         "title": {
          "text": "Safra (Ano‑Mês)"
         }
        },
        "yaxis": {
         "range": [
          0,
          1000
         ],
         "showgrid": false,
         "side": "left",
         "title": {
          "text": "Qtd. Contratos"
         }
        },
        "yaxis2": {
         "overlaying": "y",
         "range": [
          0,
          50
         ],
         "showgrid": false,
         "side": "right",
         "tickformat": ".1f",
         "title": {
          "text": "% Target (y)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_safra_e_target(\n",
    "    df,\n",
    "    id_col='id',\n",
    "    safra_col='safra',\n",
    "    target_col='y',\n",
    "    y1_range=None,\n",
    "    y2_range=None\n",
    "):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Conversão e ordenação\n",
    "    df[safra_col] = pd.to_datetime(df[safra_col].astype(str), format='%Y%m')\n",
    "    df = df.sort_values(by=safra_col)\n",
    "    df['safra_str'] = df[safra_col].dt.strftime('%Y-%m')\n",
    "\n",
    "    # 2) Agregação\n",
    "    resumo = (\n",
    "        df.groupby('safra_str', sort=False)\n",
    "          .agg(qtd_contratos=(id_col, 'count'),\n",
    "               pct_inadimplencia=(target_col, 'mean'))\n",
    "          .reset_index()\n",
    "    )\n",
    "    resumo['pct_inadimplencia'] *= 100\n",
    "\n",
    "    # 3) Hovertemplates sem repetições\n",
    "    hover_bar = '<b>Qtd. Contratos:</b> %{y:,}<extra></extra>'\n",
    "    hover_line = '<b>% Target (y):</b> %{y:.2f}%<extra></extra>'\n",
    "\n",
    "    # 4) Gráfico\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Barras – quantidade de contratos\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=resumo['safra_str'],\n",
    "        y=resumo['qtd_contratos'],\n",
    "        name='Qtd. Contratos',\n",
    "        marker_color='silver',\n",
    "        yaxis='y1',\n",
    "        hovertemplate=hover_bar\n",
    "    ))\n",
    "\n",
    "    # Linha – % target\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=resumo['safra_str'],\n",
    "        y=resumo['pct_inadimplencia'],\n",
    "        name='% Target (y)',\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='#11BF5D', width=2.5),\n",
    "        marker=dict(color='#11BF5D', size=6),\n",
    "        yaxis='y2',\n",
    "        hovertemplate=hover_line\n",
    "    ))\n",
    "\n",
    "    # 5) Layout\n",
    "    fig.update_layout(\n",
    "        title='Evolução de Novos Contratos e Taxa de Inadimplência Futura por Safra',\n",
    "        template='plotly_white',\n",
    "        height=500,\n",
    "        hovermode='x unified',\n",
    "        legend=dict(x=0.01, y=0.99, bgcolor='rgba(0,0,0,0)'),\n",
    "\n",
    "        xaxis=dict(\n",
    "            title='Safra (Ano‑Mês)',\n",
    "            tickmode='array',\n",
    "            tickvals=resumo['safra_str'],\n",
    "            ticktext=resumo['safra_str'],\n",
    "            tickangle=-45\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Qtd. Contratos',\n",
    "            side='left',\n",
    "            showgrid=False,\n",
    "            range=y1_range\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='% Target (y)',\n",
    "            side='right',\n",
    "            overlaying='y',\n",
    "            showgrid=False,\n",
    "            tickformat=\".1f\",\n",
    "            range=y2_range\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_safra_e_target(\n",
    "    raw_data,\n",
    "    y1_range=[0, 1000],\n",
    "    y2_range=[0, 50]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d797f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 📋 Resumo Comparativo Final"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_afa45_row0_col5, #T_afa45_row1_col5, #T_afa45_row2_col5, #T_afa45_row3_col5, #T_afa45_row5_col5, #T_afa45_row7_col5, #T_afa45_row8_col5, #T_afa45_row13_col5, #T_afa45_row15_col5, #T_afa45_row16_col5, #T_afa45_row17_col5, #T_afa45_row18_col5, #T_afa45_row19_col5, #T_afa45_row20_col5, #T_afa45_row21_col5, #T_afa45_row24_col5, #T_afa45_row25_col5, #T_afa45_row26_col5, #T_afa45_row27_col5, #T_afa45_row28_col5, #T_afa45_row29_col5, #T_afa45_row30_col5, #T_afa45_row31_col5, #T_afa45_row32_col5, #T_afa45_row33_col5, #T_afa45_row35_col5, #T_afa45_row36_col5, #T_afa45_row37_col5, #T_afa45_row39_col5, #T_afa45_row40_col5, #T_afa45_row41_col5, #T_afa45_row42_col5, #T_afa45_row43_col5, #T_afa45_row45_col5, #T_afa45_row47_col5, #T_afa45_row48_col5, #T_afa45_row50_col5, #T_afa45_row52_col5, #T_afa45_row53_col5, #T_afa45_row56_col5, #T_afa45_row58_col5, #T_afa45_row59_col5, #T_afa45_row60_col5, #T_afa45_row63_col5, #T_afa45_row64_col5, #T_afa45_row66_col5, #T_afa45_row67_col5, #T_afa45_row69_col5, #T_afa45_row70_col5, #T_afa45_row71_col5, #T_afa45_row72_col5, #T_afa45_row73_col5, #T_afa45_row77_col5 {\n",
       "  background-color: #4d4d4d;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_afa45\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_afa45_level0_col0\" class=\"col_heading level0 col0\" >normalidade</th>\n",
       "      <th id=\"T_afa45_level0_col1\" class=\"col_heading level0 col1\" >p_shapiro_mean</th>\n",
       "      <th id=\"T_afa45_level0_col2\" class=\"col_heading level0 col2\" >homogeneidade</th>\n",
       "      <th id=\"T_afa45_level0_col3\" class=\"col_heading level0 col3\" >p_levene</th>\n",
       "      <th id=\"T_afa45_level0_col4\" class=\"col_heading level0 col4\" >teste_usado</th>\n",
       "      <th id=\"T_afa45_level0_col5\" class=\"col_heading level0 col5\" >p_final</th>\n",
       "      <th id=\"T_afa45_level0_col6\" class=\"col_heading level0 col6\" >conclusao</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >feature</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row0\" class=\"row_heading level0 row0\" >VAR_1</th>\n",
       "      <td id=\"T_afa45_row0_col0\" class=\"data row0 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row0_col2\" class=\"data row0 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row0_col4\" class=\"data row0 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row0_col5\" class=\"data row0 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row0_col6\" class=\"data row0 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row1\" class=\"row_heading level0 row1\" >VAR_2</th>\n",
       "      <td id=\"T_afa45_row1_col0\" class=\"data row1 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row1_col2\" class=\"data row1 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row1_col4\" class=\"data row1 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row1_col5\" class=\"data row1 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row1_col6\" class=\"data row1 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row2\" class=\"row_heading level0 row2\" >VAR_3</th>\n",
       "      <td id=\"T_afa45_row2_col0\" class=\"data row2 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row2_col2\" class=\"data row2 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row2_col4\" class=\"data row2 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row2_col5\" class=\"data row2 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row2_col6\" class=\"data row2 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row3\" class=\"row_heading level0 row3\" >VAR_4</th>\n",
       "      <td id=\"T_afa45_row3_col0\" class=\"data row3 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row3_col2\" class=\"data row3 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row3_col4\" class=\"data row3 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row3_col5\" class=\"data row3 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row3_col6\" class=\"data row3 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row4\" class=\"row_heading level0 row4\" >VAR_5</th>\n",
       "      <td id=\"T_afa45_row4_col0\" class=\"data row4 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row4_col2\" class=\"data row4 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row4_col3\" class=\"data row4 col3\" >0.063900</td>\n",
       "      <td id=\"T_afa45_row4_col4\" class=\"data row4 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row4_col5\" class=\"data row4 col5\" >0.303600</td>\n",
       "      <td id=\"T_afa45_row4_col6\" class=\"data row4 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row5\" class=\"row_heading level0 row5\" >VAR_6</th>\n",
       "      <td id=\"T_afa45_row5_col0\" class=\"data row5 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row5_col2\" class=\"data row5 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row5_col3\" class=\"data row5 col3\" >0.005500</td>\n",
       "      <td id=\"T_afa45_row5_col4\" class=\"data row5 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row5_col5\" class=\"data row5 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row5_col6\" class=\"data row5 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row6\" class=\"row_heading level0 row6\" >VAR_7</th>\n",
       "      <td id=\"T_afa45_row6_col0\" class=\"data row6 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row6_col1\" class=\"data row6 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row6_col2\" class=\"data row6 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row6_col3\" class=\"data row6 col3\" >0.895900</td>\n",
       "      <td id=\"T_afa45_row6_col4\" class=\"data row6 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row6_col5\" class=\"data row6 col5\" >0.076300</td>\n",
       "      <td id=\"T_afa45_row6_col6\" class=\"data row6 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row7\" class=\"row_heading level0 row7\" >VAR_8</th>\n",
       "      <td id=\"T_afa45_row7_col0\" class=\"data row7 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row7_col1\" class=\"data row7 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row7_col2\" class=\"data row7 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row7_col3\" class=\"data row7 col3\" >0.297000</td>\n",
       "      <td id=\"T_afa45_row7_col4\" class=\"data row7 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row7_col5\" class=\"data row7 col5\" >0.000200</td>\n",
       "      <td id=\"T_afa45_row7_col6\" class=\"data row7 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row8\" class=\"row_heading level0 row8\" >VAR_9</th>\n",
       "      <td id=\"T_afa45_row8_col0\" class=\"data row8 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row8_col1\" class=\"data row8 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row8_col2\" class=\"data row8 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row8_col3\" class=\"data row8 col3\" >0.001000</td>\n",
       "      <td id=\"T_afa45_row8_col4\" class=\"data row8 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row8_col5\" class=\"data row8 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row8_col6\" class=\"data row8 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row9\" class=\"row_heading level0 row9\" >VAR_10</th>\n",
       "      <td id=\"T_afa45_row9_col0\" class=\"data row9 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row9_col1\" class=\"data row9 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row9_col2\" class=\"data row9 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row9_col3\" class=\"data row9 col3\" >0.272800</td>\n",
       "      <td id=\"T_afa45_row9_col4\" class=\"data row9 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row9_col5\" class=\"data row9 col5\" >0.323500</td>\n",
       "      <td id=\"T_afa45_row9_col6\" class=\"data row9 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row10\" class=\"row_heading level0 row10\" >VAR_11</th>\n",
       "      <td id=\"T_afa45_row10_col0\" class=\"data row10 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row10_col1\" class=\"data row10 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row10_col2\" class=\"data row10 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row10_col3\" class=\"data row10 col3\" >0.400300</td>\n",
       "      <td id=\"T_afa45_row10_col4\" class=\"data row10 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row10_col5\" class=\"data row10 col5\" >0.197900</td>\n",
       "      <td id=\"T_afa45_row10_col6\" class=\"data row10 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row11\" class=\"row_heading level0 row11\" >VAR_12</th>\n",
       "      <td id=\"T_afa45_row11_col0\" class=\"data row11 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row11_col1\" class=\"data row11 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row11_col2\" class=\"data row11 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row11_col3\" class=\"data row11 col3\" >0.207800</td>\n",
       "      <td id=\"T_afa45_row11_col4\" class=\"data row11 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row11_col5\" class=\"data row11 col5\" >0.128200</td>\n",
       "      <td id=\"T_afa45_row11_col6\" class=\"data row11 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row12\" class=\"row_heading level0 row12\" >VAR_13</th>\n",
       "      <td id=\"T_afa45_row12_col0\" class=\"data row12 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row12_col1\" class=\"data row12 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row12_col2\" class=\"data row12 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row12_col3\" class=\"data row12 col3\" >0.428200</td>\n",
       "      <td id=\"T_afa45_row12_col4\" class=\"data row12 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row12_col5\" class=\"data row12 col5\" >0.296200</td>\n",
       "      <td id=\"T_afa45_row12_col6\" class=\"data row12 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row13\" class=\"row_heading level0 row13\" >VAR_14</th>\n",
       "      <td id=\"T_afa45_row13_col0\" class=\"data row13 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row13_col1\" class=\"data row13 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row13_col2\" class=\"data row13 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row13_col3\" class=\"data row13 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row13_col4\" class=\"data row13 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row13_col5\" class=\"data row13 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row13_col6\" class=\"data row13 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row14\" class=\"row_heading level0 row14\" >VAR_15</th>\n",
       "      <td id=\"T_afa45_row14_col0\" class=\"data row14 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row14_col1\" class=\"data row14 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row14_col2\" class=\"data row14 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row14_col3\" class=\"data row14 col3\" >0.117800</td>\n",
       "      <td id=\"T_afa45_row14_col4\" class=\"data row14 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row14_col5\" class=\"data row14 col5\" >0.068400</td>\n",
       "      <td id=\"T_afa45_row14_col6\" class=\"data row14 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row15\" class=\"row_heading level0 row15\" >VAR_16</th>\n",
       "      <td id=\"T_afa45_row15_col0\" class=\"data row15 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row15_col1\" class=\"data row15 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row15_col2\" class=\"data row15 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row15_col3\" class=\"data row15 col3\" >0.875500</td>\n",
       "      <td id=\"T_afa45_row15_col4\" class=\"data row15 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row15_col5\" class=\"data row15 col5\" >0.034200</td>\n",
       "      <td id=\"T_afa45_row15_col6\" class=\"data row15 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row16\" class=\"row_heading level0 row16\" >VAR_17</th>\n",
       "      <td id=\"T_afa45_row16_col0\" class=\"data row16 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row16_col1\" class=\"data row16 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row16_col2\" class=\"data row16 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row16_col3\" class=\"data row16 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row16_col4\" class=\"data row16 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row16_col5\" class=\"data row16 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row16_col6\" class=\"data row16 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row17\" class=\"row_heading level0 row17\" >VAR_18</th>\n",
       "      <td id=\"T_afa45_row17_col0\" class=\"data row17 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row17_col1\" class=\"data row17 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row17_col2\" class=\"data row17 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row17_col3\" class=\"data row17 col3\" >0.189200</td>\n",
       "      <td id=\"T_afa45_row17_col4\" class=\"data row17 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row17_col5\" class=\"data row17 col5\" >0.000900</td>\n",
       "      <td id=\"T_afa45_row17_col6\" class=\"data row17 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row18\" class=\"row_heading level0 row18\" >VAR_19</th>\n",
       "      <td id=\"T_afa45_row18_col0\" class=\"data row18 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row18_col1\" class=\"data row18 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row18_col2\" class=\"data row18 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row18_col3\" class=\"data row18 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row18_col4\" class=\"data row18 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row18_col5\" class=\"data row18 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row18_col6\" class=\"data row18 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row19\" class=\"row_heading level0 row19\" >VAR_20</th>\n",
       "      <td id=\"T_afa45_row19_col0\" class=\"data row19 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row19_col1\" class=\"data row19 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row19_col2\" class=\"data row19 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row19_col3\" class=\"data row19 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row19_col4\" class=\"data row19 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row19_col5\" class=\"data row19 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row19_col6\" class=\"data row19 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row20\" class=\"row_heading level0 row20\" >VAR_21</th>\n",
       "      <td id=\"T_afa45_row20_col0\" class=\"data row20 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row20_col1\" class=\"data row20 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row20_col2\" class=\"data row20 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row20_col3\" class=\"data row20 col3\" >0.040900</td>\n",
       "      <td id=\"T_afa45_row20_col4\" class=\"data row20 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row20_col5\" class=\"data row20 col5\" >0.000800</td>\n",
       "      <td id=\"T_afa45_row20_col6\" class=\"data row20 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row21\" class=\"row_heading level0 row21\" >VAR_22</th>\n",
       "      <td id=\"T_afa45_row21_col0\" class=\"data row21 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row21_col1\" class=\"data row21 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row21_col2\" class=\"data row21 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row21_col3\" class=\"data row21 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row21_col4\" class=\"data row21 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row21_col5\" class=\"data row21 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row21_col6\" class=\"data row21 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row22\" class=\"row_heading level0 row22\" >VAR_23</th>\n",
       "      <td id=\"T_afa45_row22_col0\" class=\"data row22 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row22_col1\" class=\"data row22 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row22_col2\" class=\"data row22 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row22_col3\" class=\"data row22 col3\" >0.571500</td>\n",
       "      <td id=\"T_afa45_row22_col4\" class=\"data row22 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row22_col5\" class=\"data row22 col5\" >0.467400</td>\n",
       "      <td id=\"T_afa45_row22_col6\" class=\"data row22 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row23\" class=\"row_heading level0 row23\" >VAR_24</th>\n",
       "      <td id=\"T_afa45_row23_col0\" class=\"data row23 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row23_col1\" class=\"data row23 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row23_col2\" class=\"data row23 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row23_col3\" class=\"data row23 col3\" >0.000700</td>\n",
       "      <td id=\"T_afa45_row23_col4\" class=\"data row23 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row23_col5\" class=\"data row23 col5\" >0.818900</td>\n",
       "      <td id=\"T_afa45_row23_col6\" class=\"data row23 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row24\" class=\"row_heading level0 row24\" >VAR_25</th>\n",
       "      <td id=\"T_afa45_row24_col0\" class=\"data row24 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row24_col1\" class=\"data row24 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row24_col2\" class=\"data row24 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row24_col3\" class=\"data row24 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row24_col4\" class=\"data row24 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row24_col5\" class=\"data row24 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row24_col6\" class=\"data row24 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row25\" class=\"row_heading level0 row25\" >VAR_26</th>\n",
       "      <td id=\"T_afa45_row25_col0\" class=\"data row25 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row25_col1\" class=\"data row25 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row25_col2\" class=\"data row25 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row25_col3\" class=\"data row25 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row25_col4\" class=\"data row25 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row25_col5\" class=\"data row25 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row25_col6\" class=\"data row25 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row26\" class=\"row_heading level0 row26\" >VAR_27</th>\n",
       "      <td id=\"T_afa45_row26_col0\" class=\"data row26 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row26_col1\" class=\"data row26 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row26_col2\" class=\"data row26 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row26_col3\" class=\"data row26 col3\" >0.045800</td>\n",
       "      <td id=\"T_afa45_row26_col4\" class=\"data row26 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row26_col5\" class=\"data row26 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row26_col6\" class=\"data row26 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row27\" class=\"row_heading level0 row27\" >VAR_28</th>\n",
       "      <td id=\"T_afa45_row27_col0\" class=\"data row27 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row27_col1\" class=\"data row27 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row27_col2\" class=\"data row27 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row27_col3\" class=\"data row27 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row27_col4\" class=\"data row27 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row27_col5\" class=\"data row27 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row27_col6\" class=\"data row27 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row28\" class=\"row_heading level0 row28\" >VAR_29</th>\n",
       "      <td id=\"T_afa45_row28_col0\" class=\"data row28 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row28_col1\" class=\"data row28 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row28_col2\" class=\"data row28 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row28_col3\" class=\"data row28 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row28_col4\" class=\"data row28 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row28_col5\" class=\"data row28 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row28_col6\" class=\"data row28 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row29\" class=\"row_heading level0 row29\" >VAR_30</th>\n",
       "      <td id=\"T_afa45_row29_col0\" class=\"data row29 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row29_col1\" class=\"data row29 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row29_col2\" class=\"data row29 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row29_col3\" class=\"data row29 col3\" >0.464000</td>\n",
       "      <td id=\"T_afa45_row29_col4\" class=\"data row29 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row29_col5\" class=\"data row29 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row29_col6\" class=\"data row29 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row30\" class=\"row_heading level0 row30\" >VAR_31</th>\n",
       "      <td id=\"T_afa45_row30_col0\" class=\"data row30 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row30_col1\" class=\"data row30 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row30_col2\" class=\"data row30 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row30_col3\" class=\"data row30 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row30_col4\" class=\"data row30 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row30_col5\" class=\"data row30 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row30_col6\" class=\"data row30 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row31\" class=\"row_heading level0 row31\" >VAR_32</th>\n",
       "      <td id=\"T_afa45_row31_col0\" class=\"data row31 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row31_col1\" class=\"data row31 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row31_col2\" class=\"data row31 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row31_col3\" class=\"data row31 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row31_col4\" class=\"data row31 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row31_col5\" class=\"data row31 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row31_col6\" class=\"data row31 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row32\" class=\"row_heading level0 row32\" >VAR_33</th>\n",
       "      <td id=\"T_afa45_row32_col0\" class=\"data row32 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row32_col1\" class=\"data row32 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row32_col2\" class=\"data row32 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row32_col3\" class=\"data row32 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row32_col4\" class=\"data row32 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row32_col5\" class=\"data row32 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row32_col6\" class=\"data row32 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row33\" class=\"row_heading level0 row33\" >VAR_34</th>\n",
       "      <td id=\"T_afa45_row33_col0\" class=\"data row33 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row33_col1\" class=\"data row33 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row33_col2\" class=\"data row33 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row33_col3\" class=\"data row33 col3\" >0.022100</td>\n",
       "      <td id=\"T_afa45_row33_col4\" class=\"data row33 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row33_col5\" class=\"data row33 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row33_col6\" class=\"data row33 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row34\" class=\"row_heading level0 row34\" >VAR_35</th>\n",
       "      <td id=\"T_afa45_row34_col0\" class=\"data row34 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row34_col1\" class=\"data row34 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row34_col2\" class=\"data row34 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row34_col3\" class=\"data row34 col3\" >0.674900</td>\n",
       "      <td id=\"T_afa45_row34_col4\" class=\"data row34 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row34_col5\" class=\"data row34 col5\" >0.108300</td>\n",
       "      <td id=\"T_afa45_row34_col6\" class=\"data row34 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row35\" class=\"row_heading level0 row35\" >VAR_36</th>\n",
       "      <td id=\"T_afa45_row35_col0\" class=\"data row35 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row35_col1\" class=\"data row35 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row35_col2\" class=\"data row35 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row35_col3\" class=\"data row35 col3\" >0.000100</td>\n",
       "      <td id=\"T_afa45_row35_col4\" class=\"data row35 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row35_col5\" class=\"data row35 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row35_col6\" class=\"data row35 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row36\" class=\"row_heading level0 row36\" >VAR_37</th>\n",
       "      <td id=\"T_afa45_row36_col0\" class=\"data row36 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row36_col1\" class=\"data row36 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row36_col2\" class=\"data row36 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row36_col3\" class=\"data row36 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row36_col4\" class=\"data row36 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row36_col5\" class=\"data row36 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row36_col6\" class=\"data row36 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row37\" class=\"row_heading level0 row37\" >VAR_38</th>\n",
       "      <td id=\"T_afa45_row37_col0\" class=\"data row37 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row37_col1\" class=\"data row37 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row37_col2\" class=\"data row37 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row37_col3\" class=\"data row37 col3\" >0.920900</td>\n",
       "      <td id=\"T_afa45_row37_col4\" class=\"data row37 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row37_col5\" class=\"data row37 col5\" >0.005200</td>\n",
       "      <td id=\"T_afa45_row37_col6\" class=\"data row37 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row38\" class=\"row_heading level0 row38\" >VAR_39</th>\n",
       "      <td id=\"T_afa45_row38_col0\" class=\"data row38 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row38_col1\" class=\"data row38 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row38_col2\" class=\"data row38 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row38_col3\" class=\"data row38 col3\" >0.055000</td>\n",
       "      <td id=\"T_afa45_row38_col4\" class=\"data row38 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row38_col5\" class=\"data row38 col5\" >0.407500</td>\n",
       "      <td id=\"T_afa45_row38_col6\" class=\"data row38 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row39\" class=\"row_heading level0 row39\" >VAR_40</th>\n",
       "      <td id=\"T_afa45_row39_col0\" class=\"data row39 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row39_col1\" class=\"data row39 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row39_col2\" class=\"data row39 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row39_col3\" class=\"data row39 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row39_col4\" class=\"data row39 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row39_col5\" class=\"data row39 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row39_col6\" class=\"data row39 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row40\" class=\"row_heading level0 row40\" >VAR_41</th>\n",
       "      <td id=\"T_afa45_row40_col0\" class=\"data row40 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row40_col1\" class=\"data row40 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row40_col2\" class=\"data row40 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row40_col3\" class=\"data row40 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row40_col4\" class=\"data row40 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row40_col5\" class=\"data row40 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row40_col6\" class=\"data row40 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row41\" class=\"row_heading level0 row41\" >VAR_42</th>\n",
       "      <td id=\"T_afa45_row41_col0\" class=\"data row41 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row41_col1\" class=\"data row41 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row41_col2\" class=\"data row41 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row41_col3\" class=\"data row41 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row41_col4\" class=\"data row41 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row41_col5\" class=\"data row41 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row41_col6\" class=\"data row41 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row42\" class=\"row_heading level0 row42\" >VAR_43</th>\n",
       "      <td id=\"T_afa45_row42_col0\" class=\"data row42 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row42_col1\" class=\"data row42 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row42_col2\" class=\"data row42 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row42_col3\" class=\"data row42 col3\" >0.268100</td>\n",
       "      <td id=\"T_afa45_row42_col4\" class=\"data row42 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row42_col5\" class=\"data row42 col5\" >0.036800</td>\n",
       "      <td id=\"T_afa45_row42_col6\" class=\"data row42 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row43\" class=\"row_heading level0 row43\" >VAR_44</th>\n",
       "      <td id=\"T_afa45_row43_col0\" class=\"data row43 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row43_col1\" class=\"data row43 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row43_col2\" class=\"data row43 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row43_col3\" class=\"data row43 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row43_col4\" class=\"data row43 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row43_col5\" class=\"data row43 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row43_col6\" class=\"data row43 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row44\" class=\"row_heading level0 row44\" >VAR_45</th>\n",
       "      <td id=\"T_afa45_row44_col0\" class=\"data row44 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row44_col1\" class=\"data row44 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row44_col2\" class=\"data row44 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row44_col3\" class=\"data row44 col3\" >0.181900</td>\n",
       "      <td id=\"T_afa45_row44_col4\" class=\"data row44 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row44_col5\" class=\"data row44 col5\" >0.481900</td>\n",
       "      <td id=\"T_afa45_row44_col6\" class=\"data row44 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row45\" class=\"row_heading level0 row45\" >VAR_46</th>\n",
       "      <td id=\"T_afa45_row45_col0\" class=\"data row45 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row45_col1\" class=\"data row45 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row45_col2\" class=\"data row45 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row45_col3\" class=\"data row45 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row45_col4\" class=\"data row45 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row45_col5\" class=\"data row45 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row45_col6\" class=\"data row45 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row46\" class=\"row_heading level0 row46\" >VAR_47</th>\n",
       "      <td id=\"T_afa45_row46_col0\" class=\"data row46 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row46_col1\" class=\"data row46 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row46_col2\" class=\"data row46 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row46_col3\" class=\"data row46 col3\" >0.291600</td>\n",
       "      <td id=\"T_afa45_row46_col4\" class=\"data row46 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row46_col5\" class=\"data row46 col5\" >0.595200</td>\n",
       "      <td id=\"T_afa45_row46_col6\" class=\"data row46 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row47\" class=\"row_heading level0 row47\" >VAR_48</th>\n",
       "      <td id=\"T_afa45_row47_col0\" class=\"data row47 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row47_col1\" class=\"data row47 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row47_col2\" class=\"data row47 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row47_col3\" class=\"data row47 col3\" >0.023100</td>\n",
       "      <td id=\"T_afa45_row47_col4\" class=\"data row47 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row47_col5\" class=\"data row47 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row47_col6\" class=\"data row47 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row48\" class=\"row_heading level0 row48\" >VAR_49</th>\n",
       "      <td id=\"T_afa45_row48_col0\" class=\"data row48 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row48_col1\" class=\"data row48 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row48_col2\" class=\"data row48 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row48_col3\" class=\"data row48 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row48_col4\" class=\"data row48 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row48_col5\" class=\"data row48 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row48_col6\" class=\"data row48 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row49\" class=\"row_heading level0 row49\" >VAR_50</th>\n",
       "      <td id=\"T_afa45_row49_col0\" class=\"data row49 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row49_col1\" class=\"data row49 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row49_col2\" class=\"data row49 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row49_col3\" class=\"data row49 col3\" >0.889700</td>\n",
       "      <td id=\"T_afa45_row49_col4\" class=\"data row49 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row49_col5\" class=\"data row49 col5\" >0.766800</td>\n",
       "      <td id=\"T_afa45_row49_col6\" class=\"data row49 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row50\" class=\"row_heading level0 row50\" >VAR_51</th>\n",
       "      <td id=\"T_afa45_row50_col0\" class=\"data row50 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row50_col1\" class=\"data row50 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row50_col2\" class=\"data row50 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row50_col3\" class=\"data row50 col3\" >0.327300</td>\n",
       "      <td id=\"T_afa45_row50_col4\" class=\"data row50 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row50_col5\" class=\"data row50 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row50_col6\" class=\"data row50 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row51\" class=\"row_heading level0 row51\" >VAR_52</th>\n",
       "      <td id=\"T_afa45_row51_col0\" class=\"data row51 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row51_col1\" class=\"data row51 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row51_col2\" class=\"data row51 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row51_col3\" class=\"data row51 col3\" >0.438900</td>\n",
       "      <td id=\"T_afa45_row51_col4\" class=\"data row51 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row51_col5\" class=\"data row51 col5\" >0.220100</td>\n",
       "      <td id=\"T_afa45_row51_col6\" class=\"data row51 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row52\" class=\"row_heading level0 row52\" >VAR_53</th>\n",
       "      <td id=\"T_afa45_row52_col0\" class=\"data row52 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row52_col1\" class=\"data row52 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row52_col2\" class=\"data row52 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row52_col3\" class=\"data row52 col3\" >0.000800</td>\n",
       "      <td id=\"T_afa45_row52_col4\" class=\"data row52 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row52_col5\" class=\"data row52 col5\" >0.038200</td>\n",
       "      <td id=\"T_afa45_row52_col6\" class=\"data row52 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row53\" class=\"row_heading level0 row53\" >VAR_54</th>\n",
       "      <td id=\"T_afa45_row53_col0\" class=\"data row53 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row53_col1\" class=\"data row53 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row53_col2\" class=\"data row53 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row53_col3\" class=\"data row53 col3\" >0.000600</td>\n",
       "      <td id=\"T_afa45_row53_col4\" class=\"data row53 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row53_col5\" class=\"data row53 col5\" >0.039800</td>\n",
       "      <td id=\"T_afa45_row53_col6\" class=\"data row53 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row54\" class=\"row_heading level0 row54\" >VAR_55</th>\n",
       "      <td id=\"T_afa45_row54_col0\" class=\"data row54 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row54_col1\" class=\"data row54 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row54_col2\" class=\"data row54 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row54_col3\" class=\"data row54 col3\" >0.649200</td>\n",
       "      <td id=\"T_afa45_row54_col4\" class=\"data row54 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row54_col5\" class=\"data row54 col5\" >0.937500</td>\n",
       "      <td id=\"T_afa45_row54_col6\" class=\"data row54 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row55\" class=\"row_heading level0 row55\" >VAR_56</th>\n",
       "      <td id=\"T_afa45_row55_col0\" class=\"data row55 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row55_col1\" class=\"data row55 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row55_col2\" class=\"data row55 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row55_col3\" class=\"data row55 col3\" >0.994300</td>\n",
       "      <td id=\"T_afa45_row55_col4\" class=\"data row55 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row55_col5\" class=\"data row55 col5\" >0.669600</td>\n",
       "      <td id=\"T_afa45_row55_col6\" class=\"data row55 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row56\" class=\"row_heading level0 row56\" >VAR_57</th>\n",
       "      <td id=\"T_afa45_row56_col0\" class=\"data row56 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row56_col1\" class=\"data row56 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row56_col2\" class=\"data row56 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row56_col3\" class=\"data row56 col3\" >0.051500</td>\n",
       "      <td id=\"T_afa45_row56_col4\" class=\"data row56 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row56_col5\" class=\"data row56 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row56_col6\" class=\"data row56 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row57\" class=\"row_heading level0 row57\" >VAR_58</th>\n",
       "      <td id=\"T_afa45_row57_col0\" class=\"data row57 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row57_col1\" class=\"data row57 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row57_col2\" class=\"data row57 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row57_col3\" class=\"data row57 col3\" >0.000200</td>\n",
       "      <td id=\"T_afa45_row57_col4\" class=\"data row57 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row57_col5\" class=\"data row57 col5\" >0.833000</td>\n",
       "      <td id=\"T_afa45_row57_col6\" class=\"data row57 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row58\" class=\"row_heading level0 row58\" >VAR_59</th>\n",
       "      <td id=\"T_afa45_row58_col0\" class=\"data row58 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row58_col1\" class=\"data row58 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row58_col2\" class=\"data row58 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row58_col3\" class=\"data row58 col3\" >0.006800</td>\n",
       "      <td id=\"T_afa45_row58_col4\" class=\"data row58 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row58_col5\" class=\"data row58 col5\" >0.002900</td>\n",
       "      <td id=\"T_afa45_row58_col6\" class=\"data row58 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row59\" class=\"row_heading level0 row59\" >VAR_60</th>\n",
       "      <td id=\"T_afa45_row59_col0\" class=\"data row59 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row59_col1\" class=\"data row59 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row59_col2\" class=\"data row59 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row59_col3\" class=\"data row59 col3\" >0.000700</td>\n",
       "      <td id=\"T_afa45_row59_col4\" class=\"data row59 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row59_col5\" class=\"data row59 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row59_col6\" class=\"data row59 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row60\" class=\"row_heading level0 row60\" >VAR_61</th>\n",
       "      <td id=\"T_afa45_row60_col0\" class=\"data row60 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row60_col1\" class=\"data row60 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row60_col2\" class=\"data row60 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row60_col3\" class=\"data row60 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row60_col4\" class=\"data row60 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row60_col5\" class=\"data row60 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row60_col6\" class=\"data row60 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row61\" class=\"row_heading level0 row61\" >VAR_62</th>\n",
       "      <td id=\"T_afa45_row61_col0\" class=\"data row61 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row61_col1\" class=\"data row61 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row61_col2\" class=\"data row61 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row61_col3\" class=\"data row61 col3\" >0.538800</td>\n",
       "      <td id=\"T_afa45_row61_col4\" class=\"data row61 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row61_col5\" class=\"data row61 col5\" >0.196100</td>\n",
       "      <td id=\"T_afa45_row61_col6\" class=\"data row61 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row62\" class=\"row_heading level0 row62\" >VAR_63</th>\n",
       "      <td id=\"T_afa45_row62_col0\" class=\"data row62 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row62_col1\" class=\"data row62 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row62_col2\" class=\"data row62 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row62_col3\" class=\"data row62 col3\" >0.904800</td>\n",
       "      <td id=\"T_afa45_row62_col4\" class=\"data row62 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row62_col5\" class=\"data row62 col5\" >0.685400</td>\n",
       "      <td id=\"T_afa45_row62_col6\" class=\"data row62 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row63\" class=\"row_heading level0 row63\" >VAR_64</th>\n",
       "      <td id=\"T_afa45_row63_col0\" class=\"data row63 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row63_col1\" class=\"data row63 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row63_col2\" class=\"data row63 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row63_col3\" class=\"data row63 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row63_col4\" class=\"data row63 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row63_col5\" class=\"data row63 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row63_col6\" class=\"data row63 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row64\" class=\"row_heading level0 row64\" >VAR_65</th>\n",
       "      <td id=\"T_afa45_row64_col0\" class=\"data row64 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row64_col1\" class=\"data row64 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row64_col2\" class=\"data row64 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row64_col3\" class=\"data row64 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row64_col4\" class=\"data row64 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row64_col5\" class=\"data row64 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row64_col6\" class=\"data row64 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row65\" class=\"row_heading level0 row65\" >VAR_66</th>\n",
       "      <td id=\"T_afa45_row65_col0\" class=\"data row65 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row65_col1\" class=\"data row65 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row65_col2\" class=\"data row65 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row65_col3\" class=\"data row65 col3\" >0.241400</td>\n",
       "      <td id=\"T_afa45_row65_col4\" class=\"data row65 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row65_col5\" class=\"data row65 col5\" >0.401100</td>\n",
       "      <td id=\"T_afa45_row65_col6\" class=\"data row65 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row66\" class=\"row_heading level0 row66\" >VAR_67</th>\n",
       "      <td id=\"T_afa45_row66_col0\" class=\"data row66 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row66_col1\" class=\"data row66 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row66_col2\" class=\"data row66 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row66_col3\" class=\"data row66 col3\" >0.046400</td>\n",
       "      <td id=\"T_afa45_row66_col4\" class=\"data row66 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row66_col5\" class=\"data row66 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row66_col6\" class=\"data row66 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row67\" class=\"row_heading level0 row67\" >VAR_68</th>\n",
       "      <td id=\"T_afa45_row67_col0\" class=\"data row67 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row67_col1\" class=\"data row67 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row67_col2\" class=\"data row67 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row67_col3\" class=\"data row67 col3\" >0.102500</td>\n",
       "      <td id=\"T_afa45_row67_col4\" class=\"data row67 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row67_col5\" class=\"data row67 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row67_col6\" class=\"data row67 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row68\" class=\"row_heading level0 row68\" >VAR_69</th>\n",
       "      <td id=\"T_afa45_row68_col0\" class=\"data row68 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row68_col1\" class=\"data row68 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row68_col2\" class=\"data row68 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row68_col3\" class=\"data row68 col3\" >0.362900</td>\n",
       "      <td id=\"T_afa45_row68_col4\" class=\"data row68 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row68_col5\" class=\"data row68 col5\" >0.372800</td>\n",
       "      <td id=\"T_afa45_row68_col6\" class=\"data row68 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row69\" class=\"row_heading level0 row69\" >VAR_70</th>\n",
       "      <td id=\"T_afa45_row69_col0\" class=\"data row69 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row69_col1\" class=\"data row69 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row69_col2\" class=\"data row69 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row69_col3\" class=\"data row69 col3\" >0.000400</td>\n",
       "      <td id=\"T_afa45_row69_col4\" class=\"data row69 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row69_col5\" class=\"data row69 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row69_col6\" class=\"data row69 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row70\" class=\"row_heading level0 row70\" >VAR_71</th>\n",
       "      <td id=\"T_afa45_row70_col0\" class=\"data row70 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row70_col1\" class=\"data row70 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row70_col2\" class=\"data row70 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row70_col3\" class=\"data row70 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row70_col4\" class=\"data row70 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row70_col5\" class=\"data row70 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row70_col6\" class=\"data row70 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row71\" class=\"row_heading level0 row71\" >VAR_72</th>\n",
       "      <td id=\"T_afa45_row71_col0\" class=\"data row71 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row71_col1\" class=\"data row71 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row71_col2\" class=\"data row71 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row71_col3\" class=\"data row71 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row71_col4\" class=\"data row71 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row71_col5\" class=\"data row71 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row71_col6\" class=\"data row71 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row72\" class=\"row_heading level0 row72\" >VAR_73</th>\n",
       "      <td id=\"T_afa45_row72_col0\" class=\"data row72 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row72_col1\" class=\"data row72 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row72_col2\" class=\"data row72 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row72_col3\" class=\"data row72 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row72_col4\" class=\"data row72 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row72_col5\" class=\"data row72 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row72_col6\" class=\"data row72 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row73\" class=\"row_heading level0 row73\" >VAR_74</th>\n",
       "      <td id=\"T_afa45_row73_col0\" class=\"data row73 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row73_col1\" class=\"data row73 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row73_col2\" class=\"data row73 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row73_col3\" class=\"data row73 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row73_col4\" class=\"data row73 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row73_col5\" class=\"data row73 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row73_col6\" class=\"data row73 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row74\" class=\"row_heading level0 row74\" >VAR_75</th>\n",
       "      <td id=\"T_afa45_row74_col0\" class=\"data row74 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row74_col1\" class=\"data row74 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row74_col2\" class=\"data row74 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row74_col3\" class=\"data row74 col3\" >0.154700</td>\n",
       "      <td id=\"T_afa45_row74_col4\" class=\"data row74 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row74_col5\" class=\"data row74 col5\" >0.439900</td>\n",
       "      <td id=\"T_afa45_row74_col6\" class=\"data row74 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row75\" class=\"row_heading level0 row75\" >VAR_76</th>\n",
       "      <td id=\"T_afa45_row75_col0\" class=\"data row75 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row75_col1\" class=\"data row75 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row75_col2\" class=\"data row75 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row75_col3\" class=\"data row75 col3\" >0.379200</td>\n",
       "      <td id=\"T_afa45_row75_col4\" class=\"data row75 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row75_col5\" class=\"data row75 col5\" >0.418600</td>\n",
       "      <td id=\"T_afa45_row75_col6\" class=\"data row75 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row76\" class=\"row_heading level0 row76\" >VAR_77</th>\n",
       "      <td id=\"T_afa45_row76_col0\" class=\"data row76 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row76_col1\" class=\"data row76 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row76_col2\" class=\"data row76 col2\" >✅</td>\n",
       "      <td id=\"T_afa45_row76_col3\" class=\"data row76 col3\" >0.833600</td>\n",
       "      <td id=\"T_afa45_row76_col4\" class=\"data row76 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row76_col5\" class=\"data row76 col5\" >0.653400</td>\n",
       "      <td id=\"T_afa45_row76_col6\" class=\"data row76 col6\" >🟦 Sem evidência</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_afa45_level0_row77\" class=\"row_heading level0 row77\" >VAR_78</th>\n",
       "      <td id=\"T_afa45_row77_col0\" class=\"data row77 col0\" >❌</td>\n",
       "      <td id=\"T_afa45_row77_col1\" class=\"data row77 col1\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row77_col2\" class=\"data row77 col2\" >❌</td>\n",
       "      <td id=\"T_afa45_row77_col3\" class=\"data row77 col3\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row77_col4\" class=\"data row77 col4\" >Kruskal-Wallis</td>\n",
       "      <td id=\"T_afa45_row77_col5\" class=\"data row77 col5\" >0.000000</td>\n",
       "      <td id=\"T_afa45_row77_col6\" class=\"data row77 col6\" >✅ Diferença significativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d7523f3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import shapiro, levene, f_oneway, kruskal\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def avaliar_discriminacao_numerica_por_target(data, target='y', alpha=0.05, detalhar=True):\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    features = [col for col in num_cols if col != target]\n",
    "    grupos = data[target].unique()\n",
    "\n",
    "    def log_markdown(msg):\n",
    "        if detalhar:\n",
    "            display(Markdown(msg))\n",
    "\n",
    "    log_markdown(f\"## 🧪 Análise Estatística por Grupos de `{target}`\")\n",
    "    log_markdown(f\"**α (nível de significância):** {alpha:.2%}\")\n",
    "\n",
    "    # Armazenar resultados\n",
    "    resumo = []\n",
    "\n",
    "    for feature in features:\n",
    "        # Teste de Shapiro-Wilk por grupo\n",
    "        shapiro_pvals = []\n",
    "        for g in grupos:\n",
    "            try:\n",
    "                stat, pval = shapiro(data[data[target] == g][feature].dropna())\n",
    "                shapiro_pvals.append(pval)\n",
    "            except:\n",
    "                shapiro_pvals.append(1.0)  # Assume normal se erro\n",
    "        normalidade = all(p > alpha for p in shapiro_pvals)\n",
    "        p_shapiro_mean = np.mean(shapiro_pvals)\n",
    "\n",
    "        # Teste de Levene\n",
    "        grupos_data = [data[data[target] == g][feature].dropna() for g in grupos]\n",
    "        try:\n",
    "            stat_levene, p_levene = levene(*grupos_data)\n",
    "            homogeneidade = p_levene > alpha\n",
    "        except:\n",
    "            homogeneidade = False\n",
    "            p_levene = np.nan\n",
    "\n",
    "        # Escolha do teste\n",
    "        if normalidade and homogeneidade:\n",
    "            try:\n",
    "                stat_anova, p_anova = f_oneway(*grupos_data)\n",
    "                p_final = p_anova\n",
    "                teste = \"ANOVA\"\n",
    "                conclusao = \"✅ Diferença significativa\" if p_anova < alpha else \"🟦 Sem evidência\"\n",
    "            except:\n",
    "                p_final = np.nan\n",
    "                teste = \"ANOVA (erro)\"\n",
    "                conclusao = \"⚠️ Erro na ANOVA\"\n",
    "        else:\n",
    "            try:\n",
    "                stat_kw, p_kw = kruskal(*grupos_data)\n",
    "                p_final = p_kw\n",
    "                teste = \"Kruskal-Wallis\"\n",
    "                conclusao = \"✅ Diferença significativa\" if p_kw < alpha else \"🟦 Sem evidência\"\n",
    "            except:\n",
    "                p_final = np.nan\n",
    "                teste = \"Kruskal-Wallis (erro)\"\n",
    "                conclusao = \"⚠️ Erro no Kruskal\"\n",
    "\n",
    "        # Guardar no resumo\n",
    "        resumo.append({\n",
    "            'feature': feature,\n",
    "            'normalidade': \"✅\" if normalidade else \"❌\",\n",
    "            'p_shapiro_mean': round(p_shapiro_mean, 4),\n",
    "            'homogeneidade': \"✅\" if homogeneidade else \"❌\",\n",
    "            'p_levene': round(p_levene, 4) if not np.isnan(p_levene) else 'erro',\n",
    "            'teste_usado': teste,\n",
    "            'p_final': round(p_final, 4) if not np.isnan(p_final) else 'erro',\n",
    "            'conclusao': conclusao\n",
    "        })\n",
    "\n",
    "        # Detalhamento por feature\n",
    "        msg = f\"\"\"\n",
    "---  \n",
    "### 🔍 Feature: `{feature}`  \n",
    "- 🔎 **Normalidade (Shapiro-Wilk):** {\"✅\" if normalidade else \"❌\"} (p-média: {p_shapiro_mean:.3f})  \n",
    "- 📏 **Homogeneidade (Levene):** {\"✅\" if homogeneidade else \"❌\"} (p: {p_levene:.3f})  \n",
    "- 🧮 **Teste aplicado:** `{teste}`  \n",
    "- 📊 **p-valor final:** {p_final:.4f}  \n",
    "- 🧠 **Conclusão:** **{conclusao}**  \n",
    "        \"\"\"\n",
    "        log_markdown(msg)\n",
    "\n",
    "    # Mostrar resumo final\n",
    "    resumo_df = pd.DataFrame(resumo).set_index('feature')\n",
    "    display(Markdown(\"## 📋 Resumo Comparativo Final\"))\n",
    "    display(resumo_df.style.highlight_between(subset=['p_final'], left=0, right=alpha, color='#4d4d4d'))\n",
    "\n",
    "    return resumo_df\n",
    "\n",
    "resumo = avaliar_discriminacao_numerica_por_target(raw_data.drop(columns=['id', 'safra']), target='y', detalhar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82db1c",
   "metadata": {},
   "source": [
    "## Seção 3 – Análise Univariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aacf6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def plot_vif(df, threshold=15.0):\n",
    "    \"\"\"\n",
    "    Calcula e plota os VIFs das variáveis numéricas de um DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame com apenas variáveis numéricas.\n",
    "        threshold (float): Limite a partir do qual o VIF será destacado em laranja.\n",
    "    \"\"\"\n",
    "    # --- 1. Preparo dos dados: remove NAs e constantes ---\n",
    "    X = df.dropna().copy()\n",
    "    X = X.loc[:, X.std() > 0]  # remove colunas constantes (std = 0)\n",
    "\n",
    "    # Evita erro se restar menos de 2 colunas\n",
    "    if X.shape[1] < 2:\n",
    "        print(\"⚠️ Número insuficiente de variáveis com variância não nula.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Calcular VIF ---\n",
    "    vif_values = []\n",
    "    for i in range(X.shape[1]):\n",
    "        try:\n",
    "            vif = variance_inflation_factor(X.values, i)\n",
    "        except:\n",
    "            vif = np.inf\n",
    "        vif_values.append(vif)\n",
    "\n",
    "    vif_data = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'VIF': vif_values\n",
    "    }).sort_values(by='VIF', ascending=True)\n",
    "\n",
    "    # --- 3. Plotando barra a barra com cores personalizadas ---\n",
    "    plt.figure(figsize=(8, max(4, len(vif_data)*0.4)))\n",
    "\n",
    "    for i, row in enumerate(vif_data.itertuples()):\n",
    "        color = '#F28E2B' if row.VIF > threshold else '#B0B0B0'\n",
    "        plt.barh(\n",
    "            y=i,\n",
    "            width=row.VIF,\n",
    "            color=color,\n",
    "            edgecolor='black'\n",
    "        )\n",
    "        \n",
    "        # ✅ Adiciona rótulo apenas se valor for finito\n",
    "        if np.isfinite(row.VIF):\n",
    "            plt.text(row.VIF + 0.2, i, f'{row.VIF:.1f}', va='center', fontsize=9)\n",
    "\n",
    "\n",
    "    # --- 4. Eixos e estética ---\n",
    "    plt.yticks(ticks=range(len(vif_data)), labels=vif_data['feature'])\n",
    "    plt.axvline(threshold, color='#F28E2B', linestyle='--', lw=1.3, label=f'Threshold = {threshold}')\n",
    "    plt.xlabel('VIF')\n",
    "    plt.title('🔍 VIF por Feature (Multicolinearidade)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(False)\n",
    "    plt.box(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return vif_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99dda892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Critérios de exclusão:\n",
      "  • missing > 30%\n",
      "  • importância < 0.010\n",
      "  • |correlação| < 0.050\n",
      "\n",
      "🗑️  Colunas removidas (28):\n",
      "   - VAR_5                 missing=37.8%  imp=0.002  |ρ|=0.013\n",
      "   - VAR_7                 missing=43.1%  imp=0.001  |ρ|=0.023\n",
      "   - VAR_8                 missing=45.0%  imp=0.001  |ρ|=0.048\n",
      "   - VAR_10                missing=51.8%  imp=0.001  |ρ|=0.014\n",
      "   - VAR_11                missing=46.4%  imp=0.002  |ρ|=0.017\n",
      "   - VAR_12                missing=67.0%  imp=0.002  |ρ|=0.026\n",
      "   - VAR_13                missing=48.6%  imp=0.000  |ρ|=0.014\n",
      "   - VAR_15                missing=47.1%  imp=0.003  |ρ|=0.024\n",
      "   - VAR_16                missing=66.2%  imp=0.005  |ρ|=0.035\n",
      "   - VAR_24                missing=37.8%  imp=0.004  |ρ|=0.003\n",
      "   - VAR_35                missing=46.4%  imp=0.002  |ρ|=0.021\n",
      "   - VAR_38                missing=43.1%  imp=0.003  |ρ|=0.036\n",
      "   - VAR_39                missing=48.6%  imp=0.001  |ρ|=0.011\n",
      "   - VAR_43                missing=67.0%  imp=0.002  |ρ|=0.035\n",
      "   - VAR_45                missing=48.6%  imp=0.001  |ρ|=0.009\n",
      "   - VAR_50                missing=61.5%  imp=0.001  |ρ|=0.005\n",
      "   - VAR_52                missing=47.1%  imp=0.002  |ρ|=0.016\n",
      "   - VAR_55                missing=63.9%  imp=0.005  |ρ|=0.001\n",
      "   - VAR_56                missing=64.4%  imp=0.002  |ρ|=0.007\n",
      "   - VAR_58                missing=37.8%  imp=0.003  |ρ|=0.003\n",
      "   - VAR_59                missing=42.4%  imp=0.001  |ρ|=0.038\n",
      "   - VAR_62                missing=78.0%  imp=0.001  |ρ|=0.027\n",
      "   - VAR_63                missing=67.5%  imp=0.002  |ρ|=0.007\n",
      "   - VAR_66                missing=51.8%  imp=0.003  |ρ|=0.012\n",
      "   - VAR_69                missing=51.8%  imp=0.001  |ρ|=0.012\n",
      "   - VAR_75                missing=65.4%  imp=0.003  |ρ|=0.013\n",
      "   - VAR_76                missing=42.4%  imp=0.002  |ρ|=0.010\n",
      "   - VAR_77                missing=51.8%  imp=0.001  |ρ|=0.006\n",
      "\n",
      "✅ Colunas mantidas (50)\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.stats import spearmanr, pointbiserialr\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "def smart_drop_missing(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    base_missing_thr: float = 0.60,\n",
    "    min_importance: float = 0.005,\n",
    "    min_corr: float = 0.02,\n",
    "    small_ds_boost: float = 0.10,\n",
    "    sample_weight: np.ndarray = None,\n",
    "    random_state: int = 42,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    # 1. Separação X e y\n",
    "    y = df[target_col].values\n",
    "    X = df.drop(columns=[target_col])\n",
    "\n",
    "    # 2. Percentual de missing por coluna\n",
    "    miss_pct = X.isna().mean()\n",
    "\n",
    "    # 3. Correlação com o target\n",
    "    corr = {}\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            if pd.api.types.is_numeric_dtype(X[col]):\n",
    "                rho, _ = spearmanr(X[col], y, nan_policy=\"omit\")\n",
    "            else:\n",
    "                rho, _ = pointbiserialr(y, X[col].astype(\"category\").cat.codes)\n",
    "            corr[col] = abs(rho) if np.isfinite(rho) else 0.0\n",
    "        except:\n",
    "            corr[col] = 0.0\n",
    "    corr = pd.Series(corr)\n",
    "\n",
    "    # 4. Ajuste do limiar de missing\n",
    "    missing_thr = base_missing_thr - small_ds_boost if len(df) < 10_000 else base_missing_thr\n",
    "\n",
    "    # 5. Colunas categóricas para o CatBoost (opcionalmente detectadas)\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # 6. Treinamento do CatBoost\n",
    "    if sample_weight is None:\n",
    "        sample_weight = compute_sample_weight('balanced', y)\n",
    "\n",
    "    train_pool = Pool(data=X, label=y, weight=sample_weight, cat_features=cat_cols)\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=200,\n",
    "        depth=4,\n",
    "        learning_rate=0.05,\n",
    "        random_state=random_state,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(train_pool)\n",
    "\n",
    "    # 7. Importância das features\n",
    "    imp_vals = model.get_feature_importance(train_pool, type='FeatureImportance')\n",
    "    imp = pd.Series(data=imp_vals, index=X.columns)\n",
    "    imp = imp / imp.sum() if imp.sum() > 0 else imp\n",
    "\n",
    "    # 8. Lógica de exclusão\n",
    "    to_drop = (\n",
    "        (miss_pct > missing_thr) &\n",
    "        (imp < min_importance) &\n",
    "        (corr < min_corr)\n",
    "    )\n",
    "    dropped_cols = to_drop[to_drop].index.tolist()\n",
    "    kept_cols = to_drop[~to_drop].index.tolist()\n",
    "\n",
    "    # 9. Logs\n",
    "    if verbose:\n",
    "        print(\"🔍 Critérios de exclusão:\")\n",
    "        print(f\"  • missing > {missing_thr:.0%}\")\n",
    "        print(f\"  • importância < {min_importance:.3f}\")\n",
    "        print(f\"  • |correlação| < {min_corr:.3f}\")\n",
    "        print(f\"\\n🗑️  Colunas removidas ({len(dropped_cols)}):\")\n",
    "        for col in dropped_cols:\n",
    "            print(f\"   - {col:20s}  missing={miss_pct[col]:.1%}  imp={imp[col]:.3f}  |ρ|={corr[col]:.3f}\")\n",
    "        print(f\"\\n✅ Colunas mantidas ({len(kept_cols)})\")\n",
    "\n",
    "    # 10. Estatísticas finais\n",
    "    stats = pd.DataFrame({\n",
    "        'missing_pct': miss_pct,\n",
    "        'importance': imp,\n",
    "        'abs_corr': corr,\n",
    "        'dropped': to_drop\n",
    "    }).sort_values(by='missing_pct', ascending=False)\n",
    "\n",
    "    return df.drop(columns=dropped_cols), stats\n",
    "\n",
    "sample_weights = compute_sample_weight('balanced', y=raw_data['y'])\n",
    "\n",
    "df_cleaned, stats_vazios = smart_drop_missing(\n",
    "    df=raw_data.drop(columns=['id', 'safra']),\n",
    "    target_col='y',\n",
    "    base_missing_thr=0.30,\n",
    "    min_importance=0.010,\n",
    "    sample_weight=sample_weights,\n",
    "    min_corr=0.05,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Remoção posterior com condição adicional\n",
    "df = df_cleaned[df_cleaned['VAR_1'] < 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b22d1a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🔍 Foram encontradas 40 colunas com dados ausentes.\n",
      "🧮 Percentual de valores ausentes por coluna:\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pct_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAR_70</td>\n",
       "      <td>77.451949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VAR_61</td>\n",
       "      <td>72.070291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAR_49</td>\n",
       "      <td>68.500824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAR_36</td>\n",
       "      <td>68.303130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VAR_47</td>\n",
       "      <td>67.029105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VAR_21</td>\n",
       "      <td>66.831411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VAR_18</td>\n",
       "      <td>66.831411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VAR_41</td>\n",
       "      <td>65.864909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VAR_68</td>\n",
       "      <td>62.053817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VAR_48</td>\n",
       "      <td>60.131796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VAR_67</td>\n",
       "      <td>57.891269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VAR_37</td>\n",
       "      <td>57.737507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VAR_29</td>\n",
       "      <td>56.320703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VAR_31</td>\n",
       "      <td>55.288303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>VAR_42</td>\n",
       "      <td>54.684239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>VAR_46</td>\n",
       "      <td>53.640857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VAR_71</td>\n",
       "      <td>52.674355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VAR_73</td>\n",
       "      <td>52.674355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VAR_74</td>\n",
       "      <td>52.674355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VAR_51</td>\n",
       "      <td>52.674355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VAR_78</td>\n",
       "      <td>52.674355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VAR_14</td>\n",
       "      <td>52.674355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VAR_26</td>\n",
       "      <td>52.674355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VAR_27</td>\n",
       "      <td>51.960461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VAR_23</td>\n",
       "      <td>49.906645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VAR_34</td>\n",
       "      <td>44.459088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>VAR_17</td>\n",
       "      <td>41.537617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>VAR_65</td>\n",
       "      <td>19.253158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>VAR_53</td>\n",
       "      <td>17.979132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VAR_54</td>\n",
       "      <td>9.840747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>VAR_30</td>\n",
       "      <td>0.439319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>VAR_72</td>\n",
       "      <td>0.120813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>VAR_6</td>\n",
       "      <td>0.120813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>VAR_25</td>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>VAR_22</td>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VAR_19</td>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>VAR_40</td>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VAR_28</td>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>VAR_44</td>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VAR_33</td>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>VAR_9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>VAR_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>VAR_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>VAR_4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>VAR_64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>VAR_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>VAR_60</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>VAR_57</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>VAR_32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>VAR_20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>y</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index   pct_missing\n",
       "0   VAR_70   77.451949 \n",
       "1   VAR_61   72.070291 \n",
       "2   VAR_49   68.500824 \n",
       "3   VAR_36   68.303130 \n",
       "4   VAR_47   67.029105 \n",
       "5   VAR_21   66.831411 \n",
       "6   VAR_18   66.831411 \n",
       "7   VAR_41   65.864909 \n",
       "8   VAR_68   62.053817 \n",
       "9   VAR_48   60.131796 \n",
       "10  VAR_67   57.891269 \n",
       "11  VAR_37   57.737507 \n",
       "12  VAR_29   56.320703 \n",
       "13  VAR_31   55.288303 \n",
       "14  VAR_42   54.684239 \n",
       "15  VAR_46   53.640857 \n",
       "16  VAR_71   52.674355 \n",
       "17  VAR_73   52.674355 \n",
       "18  VAR_74   52.674355 \n",
       "19  VAR_51   52.674355 \n",
       "20  VAR_78   52.674355 \n",
       "21  VAR_14   52.674355 \n",
       "22  VAR_26   52.674355 \n",
       "23  VAR_27   51.960461 \n",
       "24  VAR_23   49.906645 \n",
       "25  VAR_34   44.459088 \n",
       "26  VAR_17   41.537617 \n",
       "27  VAR_65   19.253158 \n",
       "28  VAR_53   17.979132 \n",
       "29  VAR_54    9.840747 \n",
       "30  VAR_30    0.439319 \n",
       "31  VAR_72    0.120813 \n",
       "32   VAR_6    0.120813 \n",
       "33  VAR_25    0.087864 \n",
       "34  VAR_22    0.087864 \n",
       "35  VAR_19    0.087864 \n",
       "36  VAR_40    0.087864 \n",
       "37  VAR_28    0.087864 \n",
       "38  VAR_44    0.087864 \n",
       "39  VAR_33    0.087864 \n",
       "40   VAR_9    0.000000 \n",
       "41   VAR_2    0.000000 \n",
       "42   VAR_3    0.000000 \n",
       "43   VAR_4    0.000000 \n",
       "44  VAR_64    0.000000 \n",
       "45   VAR_1    0.000000 \n",
       "46  VAR_60    0.000000 \n",
       "47  VAR_57    0.000000 \n",
       "48  VAR_32    0.000000 \n",
       "49  VAR_20    0.000000 \n",
       "50       y    0.000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 📊 Análise de Dados Ausentes\n",
    "missing = (df.isna().mean() * 100).sort_values(ascending=False)\n",
    "total_missing = (missing > 0).sum()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"🔍 Foram encontradas {total_missing} colunas com dados ausentes.\")\n",
    "print(\"🧮 Percentual de valores ausentes por coluna:\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "missing = missing.to_frame('pct_missing').reset_index()\n",
    "\n",
    "display(missing.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "367604f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "def permutation_test(original: np.ndarray, imputed: np.ndarray, n_permutations: int = 1000, random_state: int | None = None) -> float:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    pooled = np.concatenate([original, imputed])\n",
    "    observed_diff = np.mean(imputed) - np.mean(original)\n",
    "    count, len_original = 0, len(original)\n",
    "    for _ in range(n_permutations):\n",
    "        permuted = rng.permutation(pooled)\n",
    "        perm_diff = np.mean(permuted[len_original:]) - np.mean(permuted[:len_original])\n",
    "        if np.abs(perm_diff) >= np.abs(observed_diff):\n",
    "            count += 1\n",
    "    return count / n_permutations\n",
    "\n",
    "class AdaptiveImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Realiza a imputação adaptativa e validada de dados ausentes em um DataFrame.\n",
    "\n",
    "    Esta classe foi projetada para ser uma solução robusta e inteligente de\n",
    "    pré-processamento, combinando múltiplas estratégias para tratar valores\n",
    "    ausentes de forma eficiente e segura.\n",
    "\n",
    "    O seu modo de operação é dividido em três pilares principais:\n",
    "    1.  **Estratégia Adaptativa**: Decide entre uma imputação simples (mediana) ou\n",
    "        uma multivariada avançada (usando IterativeImputer com LGBMRegressor) com\n",
    "        base no percentual de dados ausentes de cada coluna.\n",
    "    2.  **Imputação Vigiada**: Garante que os valores imputados não extrapolem os\n",
    "        limites observados nos dados originais (mínimo e máximo), prevenindo a\n",
    "        criação de valores absurdos.\n",
    "    3.  **Validação Estatística**: Executa um teste de permutação não paramétrico\n",
    "        para verificar se a distribuição dos valores imputados é estatisticamente\n",
    "        semelhante à dos valores originais. Se uma imputação for considerada\n",
    "        ruim, ela é revertida.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_missing : float, default=0.60\n",
    "        Percentual máximo de valores ausentes que uma coluna pode ter para ser\n",
    "        considerada para imputação. Colunas com mais `NaNs` que este limite\n",
    "        serão ignoradas e mantidas com seus valores ausentes.\n",
    "    switch_threshold : float, default=0.001\n",
    "        Limite de percentual de `NaNs` que define a estratégia de imputação.\n",
    "        - Se `0 < %NaN <= switch_threshold`: usa imputação simples (mediana).\n",
    "        - Se `%NaN > switch_threshold`: usa imputação avançada (IterativeImputer).\n",
    "    target_col : str | None, default=None\n",
    "        Nome da coluna alvo (variável dependente) do modelo. Se fornecida,\n",
    "        esta coluna será completamente ignorada no processo de imputação.\n",
    "    bounds : dict | None, default=None\n",
    "        Dicionário para fornecer limites (mínimo, máximo) manuais para colunas\n",
    "        específicas. Ex: `{'NOME_COLUNA': (min_val, max_val)}`.\n",
    "    automatic_bounds : bool, default=False\n",
    "        Se `True`, calcula automaticamente os limites para cada coluna com base\n",
    "        nos valores mínimo e máximo observados nos dados de treino. Estes\n",
    "        limites são usados para restringir os valores imputados.\n",
    "    perm_alpha : float, default=0.10\n",
    "        Nível de significância (alfa) para o teste de permutação. Se o p-valor\n",
    "        do teste for menor que `perm_alpha`, a imputação da coluna é\n",
    "        considerada estatisticamente diferente da original e será revertida.\n",
    "    n_permutations : int, default=1000\n",
    "        Número de permutações a serem realizadas no teste estatístico para\n",
    "        cálculo do p-valor.\n",
    "    random_state : int, default=42\n",
    "        Semente para os geradores de números aleatórios, garantindo a\n",
    "        reprodutibilidade dos resultados do `LGBMRegressor`, `IterativeImputer`\n",
    "        e do teste de permutação.\n",
    "    verbose : bool, default=False\n",
    "        Se `True`, imprime logs sobre as ações realizadas, como clipping,\n",
    "        colunas revertidas e o relatório do teste de permutação.\n",
    "    exclude_cols : list[str] | None, default=None\n",
    "        Lista de nomes de colunas a serem completamente ignoradas durante\n",
    "        todo o processo de imputação.\n",
    "\n",
    "    Atributos\n",
    "    ---------\n",
    "    pipeline_ : ColumnTransformer\n",
    "        O pipeline do Scikit-learn treinado que contém os imputers.\n",
    "    bounds_ : dict\n",
    "        Dicionário final com os limites (mínimo, máximo) a serem aplicados.\n",
    "    failed_cols_ : list\n",
    "        Lista de colunas cuja imputação falhou no teste de permutação e\n",
    "        foi revertida.\n",
    "    report_ : pd.DataFrame\n",
    "        DataFrame com um relatório detalhado das ações tomadas para cada coluna.\n",
    "    test_report_ : pd.DataFrame\n",
    "        DataFrame com os p-valores das colunas que passaram no teste de permutação.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 max_missing: float = 0.60,\n",
    "                 switch_threshold: float = 0.001,\n",
    "                 target_col: str | None = None,\n",
    "                 bounds: dict | None = None,\n",
    "                 automatic_bounds: bool = False,\n",
    "                 perm_alpha: float = 0.05,\n",
    "                 n_permutations: int = 1000,\n",
    "                 random_state: int = 42,\n",
    "                 verbose: bool = False,\n",
    "                 exclude_cols: list[str] | None = None\n",
    "                 ):\n",
    "        self.max_missing = max_missing\n",
    "        self.switch_threshold = switch_threshold\n",
    "        self.target_col = target_col\n",
    "        self.bounds = bounds or {}\n",
    "        self.automatic_bounds = automatic_bounds\n",
    "        self.perm_alpha = perm_alpha\n",
    "        self.n_permutations = n_permutations\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.exclude_cols = exclude_cols or []\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "            X_fit = X.copy()\n",
    "\n",
    "            # 1. Definir colunas a serem processadas\n",
    "            numeric_cols = X_fit.select_dtypes(include=\"number\").columns.tolist()\n",
    "            excluded = (self.exclude_cols or []) + ([self.target_col] if self.target_col else [])\n",
    "            self.impute_cols_ = [c for c in numeric_cols if c not in excluded]\n",
    "\n",
    "            miss_pct = X_fit[self.impute_cols_].isna().mean()\n",
    "            self.cols_to_drop_ = miss_pct[miss_pct > self.max_missing].index.tolist()\n",
    "            self.impute_cols_ = [c for c in self.impute_cols_ if c not in self.cols_to_drop_]\n",
    "            \n",
    "            self.actual_impute_cols_ = miss_pct[miss_pct > 0].index.tolist()\n",
    "            self.actual_impute_cols_ = [c for c in self.actual_impute_cols_ if c in self.impute_cols_]\n",
    "\n",
    "            if not self.actual_impute_cols_:\n",
    "                self.imputer_ = None\n",
    "                self.failed_cols_ = []\n",
    "                # Mesmo sem imputação, o relatório deve ser criado\n",
    "                self.report_ = pd.DataFrame({\"missing_pct\": miss_pct, \"action\": \"no_missing\"}).reset_index().rename(columns={\"index\": \"column\"})\n",
    "                return self\n",
    "\n",
    "            # 2. Definir e treinar o imputer\n",
    "            self.imputer_ = IterativeImputer(\n",
    "                estimator=LGBMRegressor(random_state=self.random_state, n_jobs=-1, verbose=-1),\n",
    "                max_iter=10, random_state=self.random_state\n",
    "            )\n",
    "            self.imputer_.fit(X_fit[self.impute_cols_])\n",
    "\n",
    "            # 3. Simular imputação para validação\n",
    "            X_imputed_test = self._impute_and_clip(X_fit)\n",
    "            \n",
    "            # 4. Validar com Teste de Permutação\n",
    "            self.failed_cols_ = []\n",
    "            test_pass_data = {}\n",
    "            for col in self.actual_impute_cols_:\n",
    "                mask_nan = X_fit[col].isna()\n",
    "                original_values = X_fit.loc[~mask_nan, col].values\n",
    "                imputed_values  = X_imputed_test.loc[mask_nan, col].values\n",
    "                p_value = permutation_test(original_values, imputed_values, n_permutations=self.n_permutations, random_state=self.random_state)\n",
    "                if p_value < self.perm_alpha:\n",
    "                    self.failed_cols_.append(col)\n",
    "                else:\n",
    "                    test_pass_data[col] = {\"p_value\": p_value}\n",
    "            self.test_report_ = pd.DataFrame(test_pass_data).T\n",
    "\n",
    "            # --- CORREÇÃO: Bloco que cria self.report_ foi reinserido ---\n",
    "            # 5. Geração do relatório de ações\n",
    "            def _action(c):\n",
    "                if c in self.cols_to_drop_: return \"drop\"\n",
    "                if c not in self.impute_cols_: return \"ignore\"\n",
    "                if c in self.failed_cols_: return \"impute_fail\"\n",
    "                if c in self.actual_impute_cols_: return \"iterative\"\n",
    "                return \"no_missing\"\n",
    "\n",
    "            self.report_ = pd.DataFrame({\n",
    "                \"action\": [_action(c) for c in X_fit.columns]\n",
    "            })\n",
    "            self.report_['column'] = X_fit.columns\n",
    "            # ----------------------------------------------------------------\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"Colunas a serem imputadas: {self.actual_impute_cols_}\")\n",
    "                if self.failed_cols_: print(f\"⚠️ Imputação revertida para: {self.failed_cols_}\")\n",
    "                if not self.test_report_.empty:\n",
    "                    print(\"\\n✅ Permutation Test (aprovados):\")\n",
    "                    print(self.test_report_)\n",
    "            return self\n",
    "\n",
    "    def _impute_and_clip(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Helper para imputar e aplicar clip, usado em fit e transform.\"\"\"\n",
    "        X_processed = X.copy()\n",
    "        imputable_subset = X_processed[self.impute_cols_]\n",
    "\n",
    "        # Realiza a imputação\n",
    "        imputed_array = self.imputer_.transform(imputable_subset)\n",
    "        X_imputed = pd.DataFrame(imputed_array, columns=self.impute_cols_, index=imputable_subset.index)\n",
    "\n",
    "        # Aplica o clip apenas nos valores que eram NaN\n",
    "        for col in self.actual_impute_cols_:\n",
    "            mask_nan = X[col].isna()\n",
    "            min_val = X[col].min()\n",
    "            max_val = X[col].max()\n",
    "            X_imputed.loc[mask_nan, col] = np.clip(X_imputed.loc[mask_nan, col], min_val, max_val)\n",
    "\n",
    "        # Atualiza o DataFrame original com os valores imputados e clipados\n",
    "        X_processed[self.impute_cols_] = X_imputed\n",
    "        return X_processed\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        if not hasattr(self, 'imputer_') or self.imputer_ is None:\n",
    "            return X # Nenhuma imputação foi treinada, retorna o original\n",
    "\n",
    "        # Imputa e aplica o clip\n",
    "        X_final = self._impute_and_clip(X)\n",
    "        \n",
    "        # Reverte colunas que falharam na validação do fit\n",
    "        if self.failed_cols_:\n",
    "            X_final[self.failed_cols_] = X[self.failed_cols_]\n",
    "            \n",
    "        return X_final\n",
    "\n",
    "    def plot_reduction(self, X_original: pd.DataFrame, X_imputed: pd.DataFrame, \n",
    "                        method: str = 'pca', sample_size: int = 2000):\n",
    "            \"\"\"\n",
    "            Plota a redução de dimensionalidade dos dados antes e depois da imputação,\n",
    "            garantindo que ambos os gráficos usem a mesma escala de eixos para uma \n",
    "            comparação visual justa.\n",
    "\n",
    "            Args:\n",
    "                X_original (pd.DataFrame): O DataFrame original antes da imputação.\n",
    "                X_imputed (pd.DataFrame): O DataFrame resultante após a imputação.\n",
    "                method (str): Técnica de redução: 'pca', 'kernelpca', 'tsne'.\n",
    "                sample_size (int): Tamanho da amostra para plotagem para evitar lentidão.\n",
    "            \"\"\"\n",
    "            if not hasattr(self, 'report_'):\n",
    "                print(\"O imputer precisa ser treinado primeiro (`fit` ou `fit_transform`).\")\n",
    "                return\n",
    "\n",
    "            imputed_cols = self.report_[self.report_['action'].isin(['simple', 'iterative'])]['column'].tolist()\n",
    "            if not imputed_cols:\n",
    "                print(\"Nenhuma coluna foi imputada. Não há o que plotar.\")\n",
    "                return\n",
    "\n",
    "            n_samples = min(sample_size, len(X_original))\n",
    "            if n_samples > 0:\n",
    "                sample_idx = np.random.choice(X_original.index, size=n_samples, replace=False)\n",
    "            else:\n",
    "                print(\"Não há dados suficientes para plotar.\")\n",
    "                return\n",
    "\n",
    "            df_orig = X_original.loc[sample_idx, imputed_cols].copy()\n",
    "            df_imputed = X_imputed.loc[sample_idx, imputed_cols].copy()\n",
    "\n",
    "            missing_mask_any = df_orig.isna().any(axis=1)\n",
    "            status = np.where(missing_mask_any, 'Ponto Ausente', 'Ponto Observado')\n",
    "\n",
    "            df_orig_filled = df_orig.fillna(df_orig.median())\n",
    "\n",
    "            scaler = StandardScaler().fit(df_orig_filled)\n",
    "            X_orig_scaled = scaler.transform(df_orig_filled)\n",
    "            X_imputed_scaled = scaler.transform(df_imputed)\n",
    "\n",
    "            reducers = {\n",
    "                'pca': PCA(n_components=2, random_state=self.random_state),\n",
    "                'kernelpca': KernelPCA(n_components=2, kernel='rbf', random_state=self.random_state, n_jobs=-1),\n",
    "                'tsne': TSNE(n_components=2, random_state=self.random_state, n_jobs=-1)\n",
    "            }\n",
    "            reducer = reducers.get(method.lower())\n",
    "            if reducer is None:\n",
    "                print(f\"Método '{method}' não suportado. Escolha entre 'pca', 'kernelpca', 'tsne'.\")\n",
    "                return\n",
    "\n",
    "            # --- CORREÇÃO 1: Treinar o redutor apenas uma vez ---\n",
    "            # Treina o redutor com os dados originais para definir o espaço de projeção.\n",
    "            reducer.fit(X_orig_scaled)\n",
    "            \n",
    "            # Transforma ambos os datasets usando o MESMO redutor treinado.\n",
    "            X_orig_reduced = reducer.transform(X_orig_scaled)\n",
    "            X_imputed_reduced = reducer.transform(X_imputed_scaled)\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7)) # sharey removido para controle manual\n",
    "            sns.set_style(\"whitegrid\")\n",
    "            palette = {'Ponto Observado': 'royalblue', 'Ponto Ausente': 'orangered'}\n",
    "\n",
    "            # Gráfico \"Antes\"\n",
    "            sns.scatterplot(x=X_orig_reduced[:, 0], y=X_orig_reduced[:, 1], hue=status, \n",
    "                            palette=palette, ax=ax1, alpha=0.7)\n",
    "            ax1.set_title(f'Antes da Imputação ({method.upper()})', fontsize=14)\n",
    "            ax1.set_xlabel('Componente 1')\n",
    "            ax1.set_ylabel('Componente 2')\n",
    "            ax1.legend(title='Status Original')\n",
    "\n",
    "            # Gráfico \"Depois\"\n",
    "            sns.scatterplot(x=X_imputed_reduced[:, 0], y=X_imputed_reduced[:, 1], hue=status, \n",
    "                            palette=palette, ax=ax2, alpha=0.7)\n",
    "            ax2.set_title(f'Depois da Imputação ({method.upper()})', fontsize=14)\n",
    "            ax2.set_xlabel('Componente 1')\n",
    "            ax2.set_ylabel('') # Remove o label y do segundo gráfico para limpar a visualização\n",
    "            ax2.get_legend().remove()\n",
    "            \n",
    "            # --- CORREÇÃO 2: Forçar a mesma escala nos eixos ---\n",
    "            # Concatena todos os pontos para encontrar os limites globais\n",
    "            all_points = np.concatenate([X_orig_reduced, X_imputed_reduced], axis=0)\n",
    "            \n",
    "            # Calcula os limites com uma margem de 5%\n",
    "            x_min, x_max = all_points[:, 0].min(), all_points[:, 0].max()\n",
    "            y_min, y_max = all_points[:, 1].min(), all_points[:, 1].max()\n",
    "            x_margin = (x_max - x_min) * 0.05\n",
    "            y_margin = (y_max - y_min) * 0.05\n",
    "            \n",
    "            # Aplica os mesmos limites a ambos os gráficos\n",
    "            ax1.set_xlim(x_min - x_margin, x_max + x_margin)\n",
    "            ax2.set_xlim(x_min - x_margin, x_max + x_margin)\n",
    "            ax1.set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "            ax2.set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "            \n",
    "            plt.suptitle(f'Visualização do Impacto da Imputação com {method.upper()}', fontsize=16, y=1.02)\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04eed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando treinamento do imputer ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Instancia o imputer\n",
    "imp = AdaptiveImputer(\n",
    "    max_missing=0.40,\n",
    "    switch_threshold=0.01,\n",
    "    perm_alpha=0.05,\n",
    "    exclude_cols=[\"id\", \"safra\"],\n",
    "    automatic_bounds=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 2. Treina o imputer e transforma os dados\n",
    "print(\"--- Iniciando treinamento do imputer ---\")\n",
    "clean_df = imp.fit_transform(df)\n",
    "print(\"\\n--- Treinamento concluído ---\")\n",
    "\n",
    "# 3. Plota os resultados usando o imputer recém-treinado\n",
    "print(\"\\n--- Gerando visualizações ---\")\n",
    "imp.plot_reduction(df, clean_df, method='pca')\n",
    "#imp.plot_reduction(df, clean_df, method='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "230c9869",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AdaptiveImputer' object has no attribute 'report_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m report = \u001b[43mimp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreport_\u001b[49m\n\u001b[32m      2\u001b[39m colunas_aprovadas = report[report[\u001b[33m'\u001b[39m\u001b[33maction\u001b[39m\u001b[33m'\u001b[39m].isin([\u001b[33m'\u001b[39m\u001b[33msimple\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33minteractive\u001b[39m\u001b[33m'\u001b[39m])][\u001b[33m'\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m'\u001b[39m].tolist()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mColuna\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mNulos(orig)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mNulos(limp)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMédia(orig)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMédia(limp)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMediana(orig)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<14\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMediana(limp)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<14\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMin(orig)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMin(limp)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMax(orig)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mMax(limp)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'AdaptiveImputer' object has no attribute 'report_'"
     ]
    }
   ],
   "source": [
    "report = imp.report_\n",
    "colunas_aprovadas = report[report['action'].isin(['simple','interactive'])]['column'].tolist()\n",
    "\n",
    "print(f\"{'Coluna':<10} | {'Nulos(orig)':<12} | {'Nulos(limp)':<12} | {'Média(orig)':<12} | {'Média(limp)':<12} | {'Mediana(orig)':<14} | {'Mediana(limp)':<14} | {'Min(orig)':<10} | {'Min(limp)':<10} | {'Max(orig)':<10} | {'Max(limp)':<10}\")\n",
    "print('-' * 140)\n",
    "\n",
    "# Linhas\n",
    "for col in colunas_aprovadas: \n",
    "    nulos_orig = df[col].isna().sum()\n",
    "    nulos_limp = clean_df[col].isna().sum()\n",
    "    \n",
    "    media_orig = df[col].mean()\n",
    "    media_limp = clean_df[col].mean()\n",
    "    \n",
    "    mediana_orig = df[col].median()\n",
    "    mediana_limp = clean_df[col].median()\n",
    "    \n",
    "    min_orig = df[col].min()\n",
    "    min_limp = clean_df[col].min()\n",
    "    \n",
    "    max_orig = df[col].max()\n",
    "    max_limp = clean_df[col].max()\n",
    "\n",
    "    print(f\"{col:<10} | {nulos_orig:<12} | {nulos_limp:<12} | {media_orig:<12.2f} | {media_limp:<12.2f} | {mediana_orig:<14.2f} | {mediana_limp:<14.2f} | {min_orig:<10.2f} | {min_limp:<10.2f} | {max_orig:<10.2f} | {max_limp:<10.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d1e99de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>VAR_6</th>\n",
       "      <th>VAR_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7776</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VAR_6  VAR_6\n",
       "57     NaN    NaN  \n",
       "1115   NaN    NaN  \n",
       "1950   NaN    NaN  \n",
       "2595   NaN    NaN  \n",
       "2905   NaN    NaN  \n",
       "3219   NaN    NaN  \n",
       "4624   NaN    NaN  \n",
       "5106   NaN    NaN  \n",
       "7745   NaN    NaN  \n",
       "7776   NaN    NaN  \n",
       "10310  NaN    NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col='VAR_6'\n",
    "pd.concat([df[df[col].isna()][[col]], clean_df[clean_df[col].isna()][[col]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = CreditRiskEDA(df,\n",
    "                    \"y\",\n",
    "                    numerical_cols,\n",
    "                    categorical_cols,\n",
    "                    order_by_iv=True,\n",
    "                    remove_outliers=True,\n",
    "                    independent_outlier_removal=True,\n",
    "                    plot_shap=True\n",
    "                    )\n",
    "\n",
    "eda.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_orthogonal_features(df: pd.DataFrame, dominant_feature: str, features_to_transform: list) -> pd.DataFrame:\n",
    "    \"\"\"Creates orthogonal versions of features removing linear influence of dominant feature.\"\"\"\n",
    "    if dominant_feature not in df.columns:\n",
    "        print(\n",
    "            f\"Dominant feature '{dominant_feature}' not found; skipping orthogonal features.\"\n",
    "        )\n",
    "        return df\n",
    "\n",
    "\n",
    "    print(\n",
    "        \"Creating orthogonal features with respect to '%s'...\", dominant_feature\n",
    "    )\n",
    "\n",
    "    temp_df = df[[dominant_feature] + features_to_transform].dropna()\n",
    "    if temp_df.empty:\n",
    "        print(\n",
    "            \"DataFrame is empty after dropping NaNs; cannot create orthogonal features.\"\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    created: list[str] = []\n",
    "    X_dominant_fit = temp_df[[dominant_feature]]\n",
    "    for col in features_to_transform:\n",
    "        if (\n",
    "            col == dominant_feature\n",
    "            or col not in df.columns\n",
    "            or col.startswith(\"alvo\")\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        y_target = temp_df[col]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_dominant_fit, y_target)\n",
    "\n",
    "        # Preenchemos os NaNs com 0 apenas para a predição, garantindo que o modelo não falhe.\n",
    "        predictions = model.predict(df[[dominant_feature]].fillna(0))\n",
    "\n",
    "        residuals = df[col] - predictions\n",
    "\n",
    "        new_col_name = f\"{col}_ortho_{dominant_feature}\"\n",
    "        df[new_col_name] = residuals\n",
    "        created.append(new_col_name)\n",
    "\n",
    "    if created:\n",
    "        print(\"Created %d orthogonal features.\", len(created))\n",
    "    else:\n",
    "        print(\"No orthogonal features created.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39232772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from tqdm.auto import tqdm # Para uma barra de progresso amigável\n",
    "\n",
    "# =============================================================================\n",
    "# 1. FUNÇÃO AUXILIAR PARA CRIAR A FEATURE ORTOGONAL\n",
    "# =============================================================================\n",
    "def create_orthogonal_feature(df: pd.DataFrame, dominant_feature: str, feature_to_transform: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cria uma versão ortogonal de uma feature, removendo a influência linear de uma feature dominante.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame contendo os dados.\n",
    "        dominant_feature (str): Nome da coluna da feature dominante.\n",
    "        feature_to_transform (str): Nome da coluna da feature a ser transformada.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com a nova coluna ortogonal adicionada.\n",
    "    \"\"\"\n",
    "    df_temp = df[[dominant_feature, feature_to_transform]].dropna()\n",
    "    \n",
    "    # Se não houver dados suficientes para a regressão, retorna o df original\n",
    "    if df_temp.shape[0] < 2:\n",
    "        return df\n",
    "\n",
    "    # Modelo de regressão linear para remover a influência da feature dominante\n",
    "    X_dominant = df_temp[[dominant_feature]]\n",
    "    y_target = df_temp[feature_to_transform]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_dominant, y_target)\n",
    "\n",
    "    # Preenchemos NaNs com a mediana para a predição, garantindo que o modelo não falhe.\n",
    "    # Usar a mediana é mais robusto a outliers do que a média.\n",
    "    dominant_median = df[dominant_feature].median()\n",
    "    predictions = model.predict(df[[dominant_feature]].fillna(dominant_median))\n",
    "\n",
    "    # O resíduo é a parte da feature que NÃO é explicada pela dominante\n",
    "    residuals = df[feature_to_transform] - predictions\n",
    "    \n",
    "    new_col_name = f\"{feature_to_transform}_ortho_{dominant_feature}\"\n",
    "    df[new_col_name] = residuals\n",
    "    \n",
    "    return df\n",
    "\n",
    "# =============================================================================\n",
    "# 2. FUNÇÃO PRINCIPAL DO PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "def generate_orthogonal_features_pipeline(\n",
    "    df: pd.DataFrame, \n",
    "    target_col: str, \n",
    "    shap_cumulative_threshold: float = 0.8, \n",
    "    correlation_threshold: float = 0.3\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pipeline completo para identificar features dominantes e gerar features ortogonais.\n",
    "    \"\"\"\n",
    "    print(\"Iniciando o pipeline de geração de features ortogonais...\")\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # --- PASSO 1: Identificar features e tratar NaNs ---\n",
    "    features_originais = [col for col in df.columns if col not in [target_col, 'id', 'safra'] and not col.startswith('y')]\n",
    "    \n",
    "    ### NOVO: Filtrar colunas com variância zero para evitar o warning ###\n",
    "    numeric_features = df_processed[features_originais].select_dtypes(include=np.number).columns.tolist()\n",
    "    variances = df_processed[numeric_features].var()\n",
    "    cols_com_variancia = variances[variances > 0].index.tolist()\n",
    "    cols_sem_variancia = variances[variances == 0].index.tolist()\n",
    "\n",
    "    if cols_sem_variancia:\n",
    "        print(f\"\\nAVISO: As seguintes colunas foram removidas por terem variância zero: {cols_sem_variancia}\")\n",
    "        # Mantém apenas colunas com variância e as que não são numéricas (ex: categorias)\n",
    "        non_numeric_cols = list(set(features_originais) - set(numeric_features))\n",
    "        features_originais = cols_com_variancia + non_numeric_cols\n",
    "    \n",
    "    # Preenchendo com a mediana, que é mais robusta a outliers\n",
    "    df_filled = df_processed[features_originais].fillna(df_processed[features_originais].median())\n",
    "    X = df_filled\n",
    "    y = df_processed[target_col]\n",
    "\n",
    "    # --- PASSO 2: Treinar XGBoost com sample_weights para obter SHAP values ---\n",
    "    print(\"\\n[1/4] Treinando modelo XGBoost para calcular a importância (SHAP)...\")\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y)\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42\n",
    "    )\n",
    "    xgb_model.fit(X, y, sample_weight=sample_weights)\n",
    "\n",
    "    # --- PASSO 3: Calcular SHAP e encontrar features dominantes ---\n",
    "    print(\"[2/4] Calculando SHAP values...\")\n",
    "    explainer = shap.TreeExplainer(xgb_model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    shap_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': mean_abs_shap\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    shap_importance['cumulative_importance_ratio'] = shap_importance['importance'].cumsum() / shap_importance['importance'].sum()\n",
    "    dominant_features = shap_importance[shap_importance['cumulative_importance_ratio'] <= shap_cumulative_threshold]['feature'].tolist()\n",
    "    \n",
    "    if not dominant_features:\n",
    "        dominant_features = [shap_importance.iloc[0]['feature']]\n",
    "\n",
    "    print(f\"\\nFeatures dominantes selecionadas: {dominant_features}\")\n",
    "\n",
    "    # --- PASSO 4: Loop para criar features ortogonais ---\n",
    "    print(\"\\n[3/4] Gerando features ortogonais...\")\n",
    "    created_ortho_features = set()\n",
    "\n",
    "    for dominant in tqdm(dominant_features, desc=\"Processando features dominantes\"):\n",
    "        # Agora o corrwith só será chamado com colunas que têm variância\n",
    "        correlations = df_processed[features_originais].corrwith(df_processed[dominant]).abs()\n",
    "        \n",
    "        features_to_transform = correlations[correlations > correlation_threshold].index.tolist()\n",
    "        \n",
    "        for feature_to_tx in features_to_transform:\n",
    "            if (feature_to_tx != dominant and \n",
    "                feature_to_tx != target_col and\n",
    "                feature_to_tx not in dominant_features and\n",
    "                feature_to_tx not in created_ortho_features):\n",
    "\n",
    "                df_processed = create_orthogonal_feature(df_processed, dominant, feature_to_tx)\n",
    "                new_feature_name = f\"{feature_to_tx}_ortho_{dominant}\"\n",
    "                created_ortho_features.add(new_feature_name)\n",
    "                created_ortho_features.add(feature_to_tx) \n",
    "    \n",
    "    print(\"\\n[4/4] Pipeline concluído!\")\n",
    "    print(f\"\\nTotal de novas features ortogonais criadas: {len(created_ortho_features)}\")\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# =============================================================================\n",
    "# 3. EXECUÇÃO DO PIPELINE\n",
    "# =============================================================================\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Executar o pipeline\n",
    "    df_com_ortho = generate_orthogonal_features_pipeline(\n",
    "        df=df,\n",
    "        target_col='y',\n",
    "        shap_cumulative_threshold=0.8, # Limiar de 80% da importância do SHAP\n",
    "        correlation_threshold=0.3      # Limiar de correlação de 0.3\n",
    "    )\n",
    "\n",
    "    print(f\"\\nShape do DataFrame Final: {df_com_ortho.shape}\")\n",
    "    \n",
    "    # Verificando as novas colunas criadas\n",
    "    novas_colunas = [col for col in df_com_ortho.columns if '_ortho_' in col]\n",
    "    print(\"\\nAmostra das novas features ortogonais criadas:\")\n",
    "    print(df_com_ortho[novas_colunas].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Detectar variáveis numéricas e categóricas ---\n",
    "new_numerical_cols, new_categorical_cols = search_dtypes(\n",
    "    df_com_ortho.drop(columns=['y']),  # remove identificadores e target\n",
    "    force_categorical=[],                         # permite auto-identificação\n",
    "    limite_categorico=50,                         # colunas com até 50 valores únicos = categóricas\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# --- 2. Exibir resumo organizado ---\n",
    "display(Markdown(\"### 📊 Tipos de Variáveis Detectadas\"))\n",
    "print(f\"🔢 Variáveis Numéricas: {len(new_numerical_cols)}\")\n",
    "print(f\"🔣 Variáveis Categóricas: {len(new_categorical_cols)}\")\n",
    "\n",
    "print(\"\\n🧮 Numéricas:\")\n",
    "print(\", \".join(new_numerical_cols[:10]) + (\"...\" if len(new_numerical_cols) > 10 else \"\"))\n",
    "\n",
    "print(\"\\n🔠 Categóricas:\")\n",
    "print(\", \".join(new_categorical_cols[:10]) + (\"...\" if len(new_categorical_cols) > 10 else \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1. FUNÇÃO DE AVALIAÇÃO E PLOTAGEM (MODIFICADA)\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_and_plot_metrics(model, X, y_true, dataset_name: str):\n",
    "    \"\"\"\n",
    "    Executa a avaliação completa (métricas e plots) para um dado conjunto de dados.\n",
    "\n",
    "    Args:\n",
    "        model: O modelo treinado (pipeline).\n",
    "        X (pd.DataFrame): DataFrame com as features.\n",
    "        y_true (array-like): Valores verdadeiros do alvo.\n",
    "        dataset_name (str): Nome do conjunto de dados (ex: \"Treino\" ou \"Teste\").\n",
    "    \"\"\"\n",
    "    # Realiza as previsões\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Imprime as métricas de classificação\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Métricas de Avaliação do Modelo - Conjunto de {dataset_name.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    gini = 2 * auc - 1\n",
    "    ks = ks_2samp(y_prob[y_true==1], y_prob[y_true==0]).statistic\n",
    "    \n",
    "    print(f\"MCC (Matthews Correlation Coef): {mcc:.4f}\")\n",
    "    print(f\"Precision Score                : {precision:.4f}\")\n",
    "    print(f\"AUC (Area Under ROC Curve)     : {auc:.4f}\")\n",
    "    print(f\"Gini Coefficient               : {gini:.4f}\")\n",
    "    print(f\"KS (Kolmogorov-Smirnov)        : {ks:.4f}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    # Plota a Matriz de Confusão\n",
    "    plot_confusion_matrix(y_true, y_pred, title=f'Matriz de Confusão - {dataset_name}')\n",
    "    \n",
    "    # Plota a Curva de Calibração\n",
    "    plot_calibration_curve(y_true, y_prob, title=f'Curva de Calibração - {dataset_name}')\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title='Matriz de Confusão'):\n",
    "    \"\"\"Gera e exibe uma matriz de confusão visualmente clara.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    group_counts = [f\"{value}\" for value in cm.flatten()]\n",
    "    group_percentages = [f\"{value:.2%}\" for value in cm.flatten() / np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=True, ax=ax)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_ylabel('Verdadeiro', fontsize=12)\n",
    "    ax.set_xlabel('Previsto', fontsize=12)\n",
    "    ax.xaxis.set_ticklabels(['Classe 0', 'Classe 1'])\n",
    "    ax.yaxis.set_ticklabels(['Classe 0', 'Classe 1'])\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_calibration_curve(y_true, y_prob, n_bins=10, title='Curva de Calibração'):\n",
    "    \"\"\"Plota a curva de calibração e anota o Brier Score.\"\"\"\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=n_bins, strategy='uniform')\n",
    "    brier = brier_score_loss(y_true, y_prob)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 7))\n",
    "    ax.plot(prob_pred, prob_true, marker='o', linestyle='-', label='Modelo')\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Calibração Perfeita')\n",
    "    \n",
    "    ax.text(0.95, 0.05, f'Brier Score: {brier:.4f}', \n",
    "            verticalalignment='bottom', horizontalalignment='right',\n",
    "            transform=ax.transAxes, color='black', fontsize=12,\n",
    "            bbox=dict(boxstyle='round,pad=0.3', fc='wheat', alpha=0.5))\n",
    "    \n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Probabilidade Média Prevista (por bin)', fontsize=12)\n",
    "    ax.set_ylabel('Fração de Positivos (por bin)', fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.safra.min(),raw_data.safra.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. PIPELINE DE EXECUÇÃO E AVALIAÇÃO\n",
    "# =============================================================================\n",
    "target='y'\n",
    "features = new_numerical_cols \n",
    "X = df_com_ortho[features]\n",
    "y = df_com_ortho[target]\n",
    "\n",
    "# --- 2. Divisão dos Dados em Treino e Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_com_ortho.drop('y', axis=1),\n",
    "    df_com_ortho['y'],\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y # Importante para manter a proporção no desbalanceamento\n",
    ")\n",
    "\n",
    "# --- 3. Tratamento de Features (Simplificado para CatBoost) ---\n",
    "# O CatBoost não exige pré-processamento para features categóricas.\n",
    "# Ele também lida bem com features numéricas sem scaling, mas escalar pode ajudar em alguns casos.\n",
    "# Vamos identificar quais colunas são categóricas para informar ao modelo.\n",
    "categorical_features_indices = [X_train.columns.get_loc(col) for col in new_categorical_cols]\n",
    "\n",
    "# --- 4. Cálculo de Pesos ---\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "# --- 5. Definição do Modelo CatBoost ---\n",
    "# Note que não precisamos mais do Pipeline complexo.\n",
    "from catboost import CatBoostClassifier\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=200,             # Equivalente a n_estimators\n",
    "    learning_rate=0.05,\n",
    "    depth=4,                    # Equivalente a max_depth\n",
    "    subsample=0.8,\n",
    "    rsm=0.8,                    # Equivalente a colsample_bytree\n",
    "    loss_function='Logloss',    # Equivalente a objective e eval_metric\n",
    "    random_seed=42,\n",
    "    verbose=0,                  # Para não poluir a saída\n",
    "    cat_features=categorical_features_indices # A MÁGICA ACONTECE AQUI!\n",
    ")\n",
    "\n",
    "# --- 6. Treinamento do Modelo ---\n",
    "print(\"Iniciando o treinamento do modelo CatBoost...\")\n",
    "# Passamos os pesos da mesma forma\n",
    "cat_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "print(\"Treinamento concluído.\\n\")\n",
    "\n",
    "# --- 7. AVALIAÇÃO COMPLETA PARA TREINO E TESTE ---\n",
    "# A função de avaliação funciona perfeitamente com o novo modelo\n",
    "evaluate_and_plot_metrics(cat_model, X_train, y_train, dataset_name=\"Treino\")\n",
    "evaluate_and_plot_metrics(cat_model, X_test, y_test, dataset_name=\"Teste\")\n",
    "\n",
    "# Exibe todos os gráficos gerados\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Detectar variáveis numéricas e categóricas ---\n",
    "numerical_cols, categorical_cols = search_dtypes(\n",
    "    df.drop(columns=['y']),  # remove identificadores e target\n",
    "    force_categorical=[],                         # permite auto-identificação\n",
    "    limite_categorico=50,                         # colunas com até 50 valores únicos = categóricas\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# --- 2. Exibir resumo organizado ---\n",
    "display(Markdown(\"### 📊 Tipos de Variáveis Detectadas\"))\n",
    "print(f\"🔢 Variáveis Numéricas: {len(numerical_cols)}\")\n",
    "print(f\"🔣 Variáveis Categóricas: {len(categorical_cols)}\")\n",
    "\n",
    "print(\"\\n🧮 Numéricas:\")\n",
    "print(\", \".join(numerical_cols[:10]) + (\"...\" if len(numerical_cols) > 10 else \"\"))\n",
    "\n",
    "print(\"\\n🔠 Categóricas:\")\n",
    "print(\", \".join(categorical_cols[:10]) + (\"...\" if len(categorical_cols) > 10 else \"\"))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. PIPELINE DE EXECUÇÃO E AVALIAÇÃO\n",
    "# =============================================================================\n",
    "target='y'\n",
    "features = numerical_cols \n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# --- 2. Divisão dos Dados em Treino e Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('y', axis=1),\n",
    "    df['y'],\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y # Importante para manter a proporção no desbalanceamento\n",
    ")\n",
    "\n",
    "# --- 3. Cálculo de Pesos para Amostras Desbalanceadas (apenas com dados de treino)\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "\n",
    "# --- 4. Definição do Pré-processador\n",
    "# Para as features categóricas, usaremos OneHotEncoder. WoEEncoder não é padrão no scikit-learn.\n",
    "# Se você tiver seu WoEEncoder, pode substituir 'ohe' por ele.\n",
    "numeric_features = [col for col in X_train.columns if col.startswith('num')]\n",
    "categorical_features = [col for col in X_train.columns if col.startswith('cat')]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #('num', StandardScaler(), numeric_features),\n",
    "        #('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # Mantém outras colunas, se houver\n",
    ")\n",
    "\n",
    "# --- 5. Definição do Modelo XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False, # Recomendado para versões mais novas\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- 6. Criação do Pipeline Final\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb_model)\n",
    "])\n",
    "\n",
    "# --- 7. Treinamento do Pipeline\n",
    "# Note como passamos o sample_weight para o passo do classificador\n",
    "print(\"\\nIniciando o treinamento do pipeline...\")\n",
    "model_pipeline.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n",
    "print(\"Treinamento concluído.\")\n",
    "\n",
    "# # --- 8. Realização de Previsões no Conjunto de Teste\n",
    "# y_pred_test = model_pipeline.predict(X_test)\n",
    "# y_prob_test = model_pipeline.predict_proba(X_test)[:, 1] # Probabilidade da classe 1\n",
    "\n",
    "# # --- 9. Avaliação com as Funções de Plotagem\n",
    "# print(\"Gerando gráficos de avaliação...\")\n",
    "# fig1 = plot_confusion_matrix(y_test, y_pred_test)\n",
    "# fig2 = plot_calibration_curve(y_test, y_prob_test)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# --- 5. AVALIAÇÃO COMPLETA PARA TREINO E TESTE ---\n",
    "# Avaliação no conjunto de TREINO\n",
    "evaluate_and_plot_metrics(model_pipeline, X_train, y_train, dataset_name=\"Treino\")\n",
    "\n",
    "# Avaliação no conjunto de TESTE\n",
    "evaluate_and_plot_metrics(model_pipeline, X_test, y_test, dataset_name=\"Teste\")\n",
    "\n",
    "# Exibe todos os gráficos gerados\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Detectar variáveis numéricas e categóricas ---\n",
    "new_numerical_cols, new_categorical_cols = search_dtypes(\n",
    "    df_new.drop(columns=['y']),  # remove identificadores e target\n",
    "    force_categorical=[],        # permite auto-identificação\n",
    "    limite_categorico=50,        # colunas com até 50 valores únicos = categóricas\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "eda_new = CreditRiskEDA(df_new,\n",
    "                    \"y\",\n",
    "                    new_numerical_cols,\n",
    "                    new_categorical_cols,\n",
    "                    order_by_iv=True,\n",
    "                    remove_outliers=True,\n",
    "                    independent_outlier_removal=True,\n",
    "                    plot_shap=True\n",
    "                    )\n",
    "\n",
    "eda_new.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtre apenas colunas realmente presentes no DataFrame\n",
    "num_cols_ok = [c for c in numerical_cols   if c in df.columns]\n",
    "cat_cols_ok = [c for c in categorical_cols if c in df.columns]\n",
    "\n",
    "\n",
    "inspector = FeatureRelationshipInspector(\n",
    "    df         = df,\n",
    "    target_col = \"y\",\n",
    "    num_cols   = num_cols_ok,\n",
    "    cat_cols   = cat_cols_ok\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) PDP para duas variáveis\n",
    "inspector.plot_pdp([\"VAR_1\", \"VAR_20\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de922726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Event‑rate em bins\n",
    "inspector.plot_event_rate(\"VAR_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5946a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target='y'\n",
    "feature = 'VAR_17'\n",
    "feaures = num_cols_ok \n",
    "X = df[feaures]\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "print(\"Calculating sample weights...\")\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y)\n",
    "\n",
    "print(\"Training XGBoost model...\")\n",
    "model = xgb.XGBClassifier(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model with the calculated sample weights\n",
    "model.fit(X, y, sample_weight=sample_weights)\n",
    "\n",
    "# --- Step 4: Calculate SHAP values ---\n",
    "print(\"Calculating SHAP values...\")\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# --- Step 5: Generate and save the SHAP dependence plot ---\n",
    "print(f\"Generating SHAP dependence plot for {feature}...\")\n",
    "fig, ax = plt.subplots()\n",
    "shap.plots.scatter(\n",
    "    shap_values[:, f\"{feature}\"],\n",
    "    color=shap_values,\n",
    "    show=False,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(f\"SHAP Dependence Plot for {feature}\")\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(\"shap_dependence_plot.png\")\n",
    "\n",
    "#print(\"\\nPlot successfully saved as shap_dependence_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Correlação + tabela de event‑rate\n",
    "inspector.correlation_summary(\"VAR_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809543b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_rate_binning(df, feature, target='y', bins=10):\n",
    "    \"\"\"\n",
    "    Plota a taxa de eventos (y=1) por bin da feature contínua.\n",
    "    \"\"\"\n",
    "    df = df[[feature, target]].dropna()\n",
    "    df['bin'] = pd.qcut(df[feature], q=bins, duplicates='drop')\n",
    "    resumo = df.groupby('bin')[target].agg(['mean', 'count']).reset_index()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    sns.barplot(x='bin', y='mean', data=resumo, color='#4B8BBE', ax=ax)\n",
    "    ax.set_title(f'Event Rate por Faixa - {feature}')\n",
    "    ax.set_ylabel('Taxa de Evento (y=1)')\n",
    "    ax.set_xlabel(f'Faixas de {feature}')\n",
    "    ax.grid(False)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_event_rate_binning(df, feature='VAR_20', target='y', bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b847b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec48e837",
   "metadata": {},
   "source": [
    "## Tratamento de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d781125",
   "metadata": {},
   "source": [
    "## Persona Inadimplente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca489b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV_PICPAY",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
